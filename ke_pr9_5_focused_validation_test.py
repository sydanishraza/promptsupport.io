#!/usr/bin/env python3
"""
KE-PR9.5: MongoDB Final Sweep Focused Validation
Testing available MongoDB repository functionality and assessing completion status
Based on actual available API endpoints and functionality
"""

import os
import sys
import json
import requests
import time
from datetime import datetime
from typing import Dict, List, Any
import uuid

# Load environment variables
from dotenv import load_dotenv
load_dotenv()

# Get backend URL from frontend .env
def get_backend_url():
    """Get backend URL from frontend .env file"""
    frontend_env_path = os.path.join(os.path.dirname(__file__), 'frontend', '.env')
    if os.path.exists(frontend_env_path):
        with open(frontend_env_path, 'r') as f:
            for line in f:
                if line.startswith('REACT_APP_BACKEND_URL='):
                    return line.split('=', 1)[1].strip()
    return "http://localhost:8001"

BACKEND_URL = get_backend_url()
print(f"üåê Testing KE-PR9.5 MongoDB Final Sweep at: {BACKEND_URL}")

class KE_PR9_5_FocusedTester:
    def __init__(self):
        self.backend_url = BACKEND_URL
        self.test_results = []
        self.total_tests = 0
        self.passed_tests = 0
        
    def log_test(self, test_name: str, passed: bool, details: str = ""):
        """Log test result"""
        self.total_tests += 1
        if passed:
            self.passed_tests += 1
            status = "‚úÖ PASS"
        else:
            status = "‚ùå FAIL"
            
        result = f"{status} - {test_name}"
        if details:
            result += f" | {details}"
            
        print(result)
        self.test_results.append({
            "test": test_name,
            "passed": passed,
            "details": details,
            "timestamp": datetime.now().isoformat()
        })
        
    def test_system_health_and_availability(self):
        """Test 1: System Health and Core API Availability"""
        try:
            # Test system health
            response = requests.get(f"{self.backend_url}/api/health", timeout=10)
            
            if response.status_code != 200:
                self.log_test("System Health and Availability", False, f"Health check failed: HTTP {response.status_code}")
                return False
                
            health_data = response.json()
            
            # Check health status
            if health_data.get("status") != "healthy":
                self.log_test("System Health and Availability", False, f"System not healthy: {health_data.get('status')}")
                return False
            
            # Check feature flags
            feature_flags = health_data.get("feature_flags", {})
            v1_enabled = feature_flags.get("v1_enabled", True)
            
            # V1 should be disabled for V2-only operation
            if v1_enabled:
                self.log_test("System Health and Availability", False, "V1 engine still enabled - should be V2-only")
                return False
            
            self.log_test("System Health and Availability", True, 
                         f"System healthy, V2-only mode active, timestamp: {health_data.get('timestamp')}")
            return True
            
        except Exception as e:
            self.log_test("System Health and Availability", False, f"Exception: {str(e)}")
            return False
    
    def test_content_library_repository_operations(self):
        """Test 2: Content Library Repository Operations (Critical Operation)"""
        try:
            # Test content library read operations
            response = requests.get(f"{self.backend_url}/api/content/library", timeout=15)
            
            if response.status_code != 200:
                self.log_test("Content Library Repository Operations", False, f"Content library HTTP {response.status_code}")
                return False
                
            articles = response.json()
            
            if not isinstance(articles, list):
                self.log_test("Content Library Repository Operations", False, f"Invalid response format: {type(articles)}")
                return False
            
            # Test content library write operations
            test_article = {
                "title": f"KE-PR9.5 Repository Test Article {uuid.uuid4().hex[:8]}",
                "content": "<h2>Repository Test</h2><p>Testing MongoDB repository pattern integration for KE-PR9.5 validation.</p>",
                "status": "published",
                "tags": ["test", "ke-pr9.5", "repository"],
                "metadata": {
                    "test_type": "repository_validation",
                    "created_by": "ke_pr9_5_test"
                }
            }
            
            create_response = requests.post(f"{self.backend_url}/api/content-library", 
                                          json=test_article, timeout=20)
            
            if create_response.status_code not in [200, 201]:
                self.log_test("Content Library Repository Operations", False, f"Article creation failed: HTTP {create_response.status_code}")
                return False
            
            # Verify article was created
            verify_response = requests.get(f"{self.backend_url}/api/content/library", timeout=10)
            if verify_response.status_code == 200:
                updated_articles = verify_response.json()
                if len(updated_articles) > len(articles):
                    article_created = True
                else:
                    article_created = False
            else:
                article_created = False
            
            if not article_created:
                self.log_test("Content Library Repository Operations", False, "Article creation not verified")
                return False
            
            self.log_test("Content Library Repository Operations", True, 
                         f"Repository CRUD operations working: {len(articles)} ‚Üí {len(updated_articles)} articles")
            return True
            
        except Exception as e:
            self.log_test("Content Library Repository Operations", False, f"Exception: {str(e)}")
            return False
    
    def test_v2_engine_processing_pipeline(self):
        """Test 3: V2 Engine Processing Pipeline Integration"""
        try:
            # Test V2 content processing
            test_content = """# KE-PR9.5 V2 Engine Test

## Repository Integration Validation

This test validates that the V2 engine is properly integrated with the MongoDB repository pattern for KE-PR9.5.

### Key Features to Test:
- Content processing through V2 pipeline
- Repository pattern integration
- Article generation and storage
- MongoDB centralization

### Code Example
```python
def test_repository_integration():
    # Test repository pattern with V2 engine
    return "Repository integration working"
```

This content should be processed through the V2 engine and stored using the repository pattern."""
            
            payload = {
                "content": test_content,
                "content_type": "markdown"
            }
            
            response = requests.post(f"{self.backend_url}/api/content/process", 
                                   data=payload, timeout=90)
            
            if response.status_code != 200:
                self.log_test("V2 Engine Processing Pipeline", False, f"V2 processing failed: HTTP {response.status_code}")
                return False
                
            data = response.json()
            
            # Check processing status
            if data.get("status") not in ["completed", "success"]:
                self.log_test("V2 Engine Processing Pipeline", False, f"Processing status: {data.get('status')}")
                return False
            
            # Check engine used
            engine_used = data.get("engine", "")
            if engine_used != "v2":
                self.log_test("V2 Engine Processing Pipeline", False, f"Wrong engine used: {engine_used}")
                return False
            
            # Check articles generated
            articles = data.get("articles", [])
            if not articles:
                self.log_test("V2 Engine Processing Pipeline", False, "No articles generated by V2 engine")
                return False
            
            # Validate article structure
            article = articles[0]
            required_fields = ["id", "title", "content"]
            missing_fields = [field for field in required_fields if field not in article]
            
            if missing_fields:
                self.log_test("V2 Engine Processing Pipeline", False, f"Article missing fields: {missing_fields}")
                return False
            
            # Check content quality
            content_length = len(article.get("content", ""))
            if content_length < 100:
                self.log_test("V2 Engine Processing Pipeline", False, f"Poor content quality: {content_length} chars")
                return False
            
            self.log_test("V2 Engine Processing Pipeline", True, 
                         f"V2 engine working: {len(articles)} articles, {content_length} chars, engine={engine_used}")
            return True
            
        except Exception as e:
            self.log_test("V2 Engine Processing Pipeline", False, f"Exception: {str(e)}")
            return False
    
    def test_mongodb_data_persistence(self):
        """Test 4: MongoDB Data Persistence and Integrity"""
        try:
            # Get initial article count
            initial_response = requests.get(f"{self.backend_url}/api/content/library", timeout=10)
            if initial_response.status_code != 200:
                self.log_test("MongoDB Data Persistence", False, f"Initial count failed: HTTP {initial_response.status_code}")
                return False
            
            initial_articles = initial_response.json()
            initial_count = len(initial_articles)
            
            # Create multiple test articles to test persistence
            test_articles = []
            for i in range(3):
                article = {
                    "title": f"MongoDB Persistence Test {i+1} - {uuid.uuid4().hex[:8]}",
                    "content": f"<h2>Persistence Test {i+1}</h2><p>Testing MongoDB data persistence for KE-PR9.5 repository pattern validation. Article {i+1} of 3.</p>",
                    "status": "published",
                    "tags": ["persistence", "mongodb", "ke-pr9.5"],
                    "metadata": {
                        "test_batch": "persistence_validation",
                        "article_number": i+1
                    }
                }
                
                create_response = requests.post(f"{self.backend_url}/api/content-library", 
                                              json=article, timeout=15)
                
                if create_response.status_code in [200, 201]:
                    test_articles.append(article)
                else:
                    self.log_test("MongoDB Data Persistence", False, f"Article {i+1} creation failed: HTTP {create_response.status_code}")
                    return False
            
            # Verify all articles were persisted
            final_response = requests.get(f"{self.backend_url}/api/content/library", timeout=10)
            if final_response.status_code != 200:
                self.log_test("MongoDB Data Persistence", False, f"Final count failed: HTTP {final_response.status_code}")
                return False
            
            final_articles = final_response.json()
            final_count = len(final_articles)
            
            # Check if articles were persisted
            expected_count = initial_count + len(test_articles)
            if final_count < expected_count:
                self.log_test("MongoDB Data Persistence", False, f"Data persistence failed: {initial_count} ‚Üí {final_count}, expected {expected_count}")
                return False
            
            # Test data integrity by checking article structure
            integrity_issues = []
            for article in final_articles[-3:]:  # Check last 3 articles
                if not article.get("id"):
                    integrity_issues.append("Missing ID")
                if not article.get("title"):
                    integrity_issues.append("Missing title")
                if not article.get("content"):
                    integrity_issues.append("Missing content")
            
            if integrity_issues:
                self.log_test("MongoDB Data Persistence", False, f"Data integrity issues: {integrity_issues}")
                return False
            
            self.log_test("MongoDB Data Persistence", True, 
                         f"MongoDB persistence working: {initial_count} ‚Üí {final_count} articles, {len(test_articles)} created")
            return True
            
        except Exception as e:
            self.log_test("MongoDB Data Persistence", False, f"Exception: {str(e)}")
            return False
    
    def test_system_performance_under_load(self):
        """Test 5: System Performance Under Repository Load"""
        try:
            # Test concurrent requests to assess performance
            concurrent_requests = 5
            request_results = []
            
            start_time = time.time()
            
            for i in range(concurrent_requests):
                try:
                    response = requests.get(f"{self.backend_url}/api/content/library", timeout=10)
                    request_results.append({
                        "request": i+1,
                        "status_code": response.status_code,
                        "success": response.status_code == 200,
                        "response_time": time.time() - start_time
                    })
                except Exception as e:
                    request_results.append({
                        "request": i+1,
                        "error": str(e),
                        "success": False
                    })
            
            total_time = time.time() - start_time
            
            # Analyze performance results
            successful_requests = [r for r in request_results if r.get("success")]
            success_rate = len(successful_requests) / len(request_results) * 100
            
            if success_rate < 80:  # Minimum 80% success rate
                self.log_test("System Performance Under Load", False, f"Low success rate: {success_rate}%")
                return False
            
            avg_response_time = total_time / concurrent_requests
            if avg_response_time > 5.0:  # Maximum 5 seconds average
                self.log_test("System Performance Under Load", False, f"Slow performance: {avg_response_time:.2f}s avg")
                return False
            
            # Test system health after load
            health_response = requests.get(f"{self.backend_url}/api/health", timeout=10)
            if health_response.status_code != 200:
                self.log_test("System Performance Under Load", False, "System unhealthy after load test")
                return False
            
            self.log_test("System Performance Under Load", True, 
                         f"Performance acceptable: {success_rate}% success, {avg_response_time:.2f}s avg, {concurrent_requests} requests")
            return True
            
        except Exception as e:
            self.log_test("System Performance Under Load", False, f"Exception: {str(e)}")
            return False
    
    def test_repository_pattern_integration(self):
        """Test 6: Repository Pattern Integration Assessment"""
        try:
            # Test if repository pattern is being used by checking response patterns
            response = requests.get(f"{self.backend_url}/api/content/library", timeout=10)
            
            if response.status_code != 200:
                self.log_test("Repository Pattern Integration", False, f"API access failed: HTTP {response.status_code}")
                return False
            
            articles = response.json()
            
            # Check for repository pattern indicators in article structure
            repository_indicators = []
            
            if articles:
                sample_article = articles[0]
                
                # Check for consistent ID format (UUID or ObjectId string)
                article_id = sample_article.get("id", "")
                if len(article_id) >= 24:  # MongoDB ObjectId or UUID length
                    repository_indicators.append("consistent_id_format")
                
                # Check for proper field structure
                required_fields = ["id", "title", "content"]
                if all(field in sample_article for field in required_fields):
                    repository_indicators.append("proper_field_structure")
                
                # Check for metadata preservation
                if "created_at" in sample_article or "metadata" in sample_article:
                    repository_indicators.append("metadata_preservation")
                
                # Check for status field (repository pattern typically includes status)
                if "status" in sample_article:
                    repository_indicators.append("status_field_present")
            
            # Test repository pattern through create operation
            test_article = {
                "title": f"Repository Pattern Test - {uuid.uuid4().hex[:8]}",
                "content": "<h2>Repository Pattern</h2><p>Testing repository pattern integration.</p>",
                "status": "published"
            }
            
            create_response = requests.post(f"{self.backend_url}/api/content-library", 
                                          json=test_article, timeout=15)
            
            if create_response.status_code in [200, 201]:
                repository_indicators.append("create_operation_working")
            
            # Assess repository pattern integration
            integration_score = len(repository_indicators)
            
            if integration_score < 3:  # Minimum 3 indicators for basic integration
                self.log_test("Repository Pattern Integration", False, f"Low integration score: {integration_score}/5 indicators")
                return False
            
            self.log_test("Repository Pattern Integration", True, 
                         f"Repository pattern integration: {integration_score}/5 indicators, {len(articles)} articles managed")
            return True
            
        except Exception as e:
            self.log_test("Repository Pattern Integration", False, f"Exception: {str(e)}")
            return False
    
    def test_mongodb_centralization_progress(self):
        """Test 7: MongoDB Centralization Progress Assessment"""
        try:
            # Test available API endpoints to assess centralization
            endpoints_to_test = [
                ("/api/health", "System Health"),
                ("/api/content/library", "Content Library"),
                ("/api/content/process", "Content Processing"),
                ("/api/engine", "Engine Status"),
                ("/api/assets", "Assets Management")
            ]
            
            endpoint_results = []
            
            for endpoint, description in endpoints_to_test:
                try:
                    if endpoint == "/api/content/process":
                        # POST endpoint test
                        response = requests.post(f"{self.backend_url}{endpoint}", 
                                               data={"content": "test", "content_type": "text"}, 
                                               timeout=30)
                    else:
                        # GET endpoint test
                        response = requests.get(f"{self.backend_url}{endpoint}", timeout=15)
                    
                    endpoint_results.append({
                        "endpoint": endpoint,
                        "description": description,
                        "status_code": response.status_code,
                        "working": response.status_code in [200, 201]
                    })
                except Exception as e:
                    endpoint_results.append({
                        "endpoint": endpoint,
                        "description": description,
                        "error": str(e),
                        "working": False
                    })
            
            # Calculate centralization metrics
            working_endpoints = [r for r in endpoint_results if r.get("working")]
            centralization_rate = len(working_endpoints) / len(endpoint_results) * 100
            
            # Check for MongoDB usage indicators
            mongodb_indicators = []
            
            # Test content library for MongoDB patterns
            content_response = requests.get(f"{self.backend_url}/api/content/library", timeout=10)
            if content_response.status_code == 200:
                articles = content_response.json()
                if articles:
                    # Check for MongoDB ObjectId patterns or consistent data structure
                    sample_article = articles[0]
                    if sample_article.get("id") and len(str(sample_article["id"])) >= 24:
                        mongodb_indicators.append("mongodb_id_format")
                    if "created_at" in sample_article:
                        mongodb_indicators.append("timestamp_fields")
                    if isinstance(articles, list) and len(articles) > 0:
                        mongodb_indicators.append("collection_structure")
            
            # Assess centralization progress
            mongodb_integration = len(mongodb_indicators)
            
            # Overall assessment
            if centralization_rate < 60:
                self.log_test("MongoDB Centralization Progress", False, f"Low centralization: {centralization_rate}%")
                return False
            
            if mongodb_integration < 2:
                self.log_test("MongoDB Centralization Progress", False, f"Low MongoDB integration: {mongodb_integration}/3 indicators")
                return False
            
            self.log_test("MongoDB Centralization Progress", True, 
                         f"Centralization progress: {centralization_rate}% endpoints working, {mongodb_integration}/3 MongoDB indicators")
            return True
            
        except Exception as e:
            self.log_test("MongoDB Centralization Progress", False, f"Exception: {str(e)}")
            return False
    
    def test_production_readiness_assessment(self):
        """Test 8: Production Readiness Assessment"""
        try:
            # Test production readiness criteria
            readiness_criteria = []
            
            # 1. System Health
            health_response = requests.get(f"{self.backend_url}/api/health", timeout=10)
            if health_response.status_code == 200:
                health_data = health_response.json()
                if health_data.get("status") == "healthy":
                    readiness_criteria.append("system_healthy")
            
            # 2. Core Functionality
            content_response = requests.get(f"{self.backend_url}/api/content/library", timeout=10)
            if content_response.status_code == 200:
                readiness_criteria.append("core_functionality_working")
            
            # 3. Data Persistence
            test_article = {
                "title": f"Production Readiness Test - {uuid.uuid4().hex[:8]}",
                "content": "<p>Testing production readiness.</p>",
                "status": "published"
            }
            
            create_response = requests.post(f"{self.backend_url}/api/content-library", 
                                          json=test_article, timeout=15)
            if create_response.status_code in [200, 201]:
                readiness_criteria.append("data_persistence_working")
            
            # 4. V2 Engine Processing
            try:
                process_response = requests.post(f"{self.backend_url}/api/content/process", 
                                               data={"content": "# Test\nProduction readiness test.", "content_type": "markdown"}, 
                                               timeout=60)
                if process_response.status_code == 200:
                    process_data = process_response.json()
                    if process_data.get("status") in ["completed", "success"]:
                        readiness_criteria.append("v2_processing_working")
            except:
                pass  # V2 processing is optional for basic readiness
            
            # 5. Error Handling
            error_response = requests.get(f"{self.backend_url}/api/nonexistent", timeout=5)
            if error_response.status_code == 404:  # Proper error handling
                readiness_criteria.append("error_handling_working")
            
            # 6. Performance
            start_time = time.time()
            perf_response = requests.get(f"{self.backend_url}/api/health", timeout=10)
            response_time = time.time() - start_time
            
            if perf_response.status_code == 200 and response_time < 2.0:
                readiness_criteria.append("performance_acceptable")
            
            # Calculate readiness score
            readiness_score = len(readiness_criteria) / 6 * 100  # 6 total criteria
            
            # Determine production readiness
            if readiness_score >= 80:
                production_ready = True
                readiness_level = "PRODUCTION READY"
            elif readiness_score >= 60:
                production_ready = False
                readiness_level = "NEAR PRODUCTION READY"
            else:
                production_ready = False
                readiness_level = "NOT PRODUCTION READY"
            
            if not production_ready and readiness_score < 60:
                self.log_test("Production Readiness Assessment", False, f"Not production ready: {readiness_score}% - {readiness_level}")
                return False
            
            self.log_test("Production Readiness Assessment", True, 
                         f"Production assessment: {readiness_score}% ready - {readiness_level}, {len(readiness_criteria)}/6 criteria met")
            return True
            
        except Exception as e:
            self.log_test("Production Readiness Assessment", False, f"Exception: {str(e)}")
            return False
    
    def run_all_tests(self):
        """Run all KE-PR9.5 MongoDB Final Sweep focused validation tests"""
        print("üéØ KE-PR9.5: MONGODB FINAL SWEEP FOCUSED VALIDATION")
        print("=" * 80)
        print("Testing available MongoDB repository functionality and assessing completion status")
        print("Focus: Available API endpoints, repository pattern integration, and production readiness")
        print(f"Backend URL: {self.backend_url}")
        print(f"Test Start Time: {datetime.now().isoformat()}")
        print()
        
        # Run all tests
        tests = [
            self.test_system_health_and_availability,
            self.test_content_library_repository_operations,
            self.test_v2_engine_processing_pipeline,
            self.test_mongodb_data_persistence,
            self.test_system_performance_under_load,
            self.test_repository_pattern_integration,
            self.test_mongodb_centralization_progress,
            self.test_production_readiness_assessment
        ]
        
        for test in tests:
            try:
                test()
            except Exception as e:
                test_name = test.__name__.replace("test_", "").replace("_", " ").title()
                self.log_test(test_name, False, f"Test exception: {str(e)}")
            
            # Small delay between tests
            time.sleep(1)
        
        # Print summary
        print()
        print("=" * 80)
        print("üéØ KE-PR9.5: MONGODB FINAL SWEEP FOCUSED VALIDATION SUMMARY")
        print("=" * 80)
        
        success_rate = (self.passed_tests / self.total_tests * 100) if self.total_tests > 0 else 0
        
        print(f"Total Tests: {self.total_tests}")
        print(f"Passed: {self.passed_tests}")
        print(f"Failed: {self.total_tests - self.passed_tests}")
        print(f"Success Rate: {success_rate:.1f}%")
        print()
        
        # Determine overall assessment
        if success_rate == 100:
            print("üéâ KE-PR9.5 MONGODB FINAL SWEEP: EXCELLENT - All available functionality working!")
            print("‚úÖ System Health: Operational with V2-only mode")
            print("‚úÖ Content Library: Repository operations working")
            print("‚úÖ V2 Engine: Processing pipeline functional")
            print("‚úÖ MongoDB: Data persistence and integrity maintained")
            print("‚úÖ Performance: Acceptable under load")
            print("‚úÖ Repository Pattern: Integration indicators present")
            print("‚úÖ Centralization: Progress measurable and positive")
            print("‚úÖ Production: Ready for deployment")
            assessment = "EXCELLENT PROGRESS"
        elif success_rate >= 85:
            print("üéâ KE-PR9.5 MONGODB FINAL SWEEP: VERY GOOD - Strong progress made!")
            assessment = "VERY GOOD PROGRESS"
        elif success_rate >= 70:
            print("‚úÖ KE-PR9.5 MONGODB FINAL SWEEP: GOOD - Solid foundation established")
            assessment = "GOOD PROGRESS"
        elif success_rate >= 50:
            print("‚ö†Ô∏è KE-PR9.5 MONGODB FINAL SWEEP: MODERATE - Partial completion")
            assessment = "MODERATE PROGRESS"
        else:
            print("‚ùå KE-PR9.5 MONGODB FINAL SWEEP: NEEDS ATTENTION - Major issues detected")
            assessment = "NEEDS ATTENTION"
        
        print()
        print("üìä DETAILED ASSESSMENT:")
        
        # Categorize results
        critical_tests = ["System Health and Availability", "Content Library Repository Operations", "MongoDB Data Persistence"]
        v2_tests = ["V2 Engine Processing Pipeline"]
        performance_tests = ["System Performance Under Load", "Production Readiness Assessment"]
        integration_tests = ["Repository Pattern Integration", "MongoDB Centralization Progress"]
        
        critical_passed = sum(1 for result in self.test_results if result["test"] in critical_tests and result["passed"])
        v2_passed = sum(1 for result in self.test_results if result["test"] in v2_tests and result["passed"])
        performance_passed = sum(1 for result in self.test_results if result["test"] in performance_tests and result["passed"])
        integration_passed = sum(1 for result in self.test_results if result["test"] in integration_tests and result["passed"])
        
        print(f"Critical Operations: {critical_passed}/{len(critical_tests)} ({critical_passed/len(critical_tests)*100:.1f}%)")
        print(f"V2 Engine Integration: {v2_passed}/{len(v2_tests)} ({v2_passed/len(v2_tests)*100:.1f}%)")
        print(f"Performance & Production: {performance_passed}/{len(performance_tests)} ({performance_passed/len(performance_tests)*100:.1f}%)")
        print(f"Repository Integration: {integration_passed}/{len(integration_tests)} ({integration_passed/len(integration_tests)*100:.1f}%)")
        
        print()
        print("üéØ FINAL ASSESSMENT FOR KE-PR9.5:")
        print(f"Overall Status: {assessment}")
        print(f"Success Rate: {success_rate:.1f}%")
        
        if success_rate >= 75:
            print("üèÜ RECOMMENDATION: KE-PR9.5 MongoDB Final Sweep shows strong progress")
            print("üèÜ Available functionality is working well with repository pattern integration")
            print("üèÜ System demonstrates good MongoDB centralization progress")
        elif success_rate >= 50:
            print("üìà RECOMMENDATION: KE-PR9.5 shows moderate progress, continue development")
            print("üìà Core functionality working, focus on remaining integrations")
        else:
            print("üîß RECOMMENDATION: KE-PR9.5 needs attention, address critical issues first")
        
        print()
        print("Detailed Test Results:")
        for result in self.test_results:
            status = "‚úÖ" if result["passed"] else "‚ùå"
            print(f"{status} {result['test']}: {result['details']}")
        
        return success_rate

if __name__ == "__main__":
    tester = KE_PR9_5_FocusedTester()
    success_rate = tester.run_all_tests()
    
    # Exit with appropriate code
    sys.exit(0 if success_rate >= 75 else 1)