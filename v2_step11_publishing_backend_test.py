#!/usr/bin/env python3
"""
V2 Engine Step 11 Publishing Flow (V2 only) - Comprehensive Backend Testing
Tests the V2-only publishing system with content validation, coverage verification, and content library persistence
"""

import asyncio
import aiohttp
import json
import time
import uuid
from datetime import datetime
from typing import Dict, Any, List

# Backend URL from environment
BACKEND_URL = "https://content-pipeline-4.preview.emergentagent.com"

class V2Step11PublishingTester:
    def __init__(self):
        self.backend_url = BACKEND_URL
        self.test_results = []
        self.session = None
        
    async def setup_session(self):
        """Setup HTTP session for testing"""
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=300),  # 5 minute timeout
            headers={'Content-Type': 'application/json'}
        )
    
    async def cleanup_session(self):
        """Cleanup HTTP session"""
        if self.session:
            await self.session.close()
    
    def log_test_result(self, test_name: str, success: bool, details: str, data: Dict = None):
        """Log test result with details"""
        result = {
            "test": test_name,
            "success": success,
            "details": details,
            "timestamp": datetime.utcnow().isoformat(),
            "data": data or {}
        }
        self.test_results.append(result)
        
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"{status} | {test_name}")
        print(f"   Details: {details}")
        if data and success:
            print(f"   Data: {json.dumps(data, indent=2)[:200]}...")
        print()
    
    async def test_v2_engine_health_check(self):
        """Test V2 Engine is active and ready for publishing tests"""
        try:
            async with self.session.get(f"{self.backend_url}/api/engine") as response:
                if response.status == 200:
                    data = await response.json()
                    engine = data.get('engine')
                    status = data.get('status')
                    
                    if engine == 'v2' and status == 'active':
                        self.log_test_result(
                            "V2 Engine Health Check",
                            True,
                            f"V2 Engine active and ready for publishing tests - engine={engine}, status={status}",
                            {"engine": engine, "status": status}
                        )
                        return True
                    else:
                        self.log_test_result(
                            "V2 Engine Health Check",
                            False,
                            f"V2 Engine not properly configured - engine={engine}, status={status}",
                            data
                        )
                        return False
                else:
                    self.log_test_result(
                        "V2 Engine Health Check",
                        False,
                        f"Health check failed with status {response.status}",
                        {"status_code": response.status}
                    )
                    return False
        except Exception as e:
            self.log_test_result(
                "V2 Engine Health Check",
                False,
                f"Health check error: {str(e)}",
                {"error": str(e)}
            )
            return False
    
    async def test_v2_text_processing_with_publishing(self):
        """Test V2 text processing pipeline with Step 11 publishing integration"""
        try:
            # Create comprehensive test content for V2 publishing
            test_content = """
            # V2 Publishing System Integration Guide
            
            This comprehensive guide covers the V2-only publishing system implementation for content persistence and single source of truth management.
            
            ## Overview
            The V2 publishing system ensures that only validated V2 content with 100% coverage is published to the content library.
            
            ## Key Features
            - V2-only content validation
            - 100% coverage requirement verification
            - Comprehensive content library structure
            - Publishing diagnostics and monitoring
            - Media reference handling without embedding
            
            ## Implementation Details
            The publishing system validates engine=v2, processing_version=2.0, and generated_by=v2_article_generator for all content.
            
            ## Coverage Requirements
            All content must achieve 100% coverage before publishing is allowed. This ensures complete fidelity to source material.
            
            ## Content Library Structure
            Published articles include HTML, markdown, TOC with anchors, FAQ structure, related links, provenance map, comprehensive metrics, and media references.
            
            ## Quality Assurance
            The system prevents v1 contamination and ensures V2-only content reaches the content library as the single source of truth.
            """
            
            request_data = {
                "content": test_content,
                "metadata": {
                    "title": "V2 Publishing System Test",
                    "source": "v2_step11_test",
                    "test_type": "publishing_integration"
                }
            }
            
            print(f"ğŸš€ Testing V2 text processing with publishing integration...")
            start_time = time.time()
            
            async with self.session.post(
                f"{self.backend_url}/api/content/process",
                json=request_data
            ) as response:
                processing_time = time.time() - start_time
                
                if response.status == 200:
                    data = await response.json()
                    engine = data.get('engine')
                    status = data.get('status')
                    job_id = data.get('job_id')
                    
                    if engine == 'v2' and status == 'completed':
                        self.log_test_result(
                            "V2 Text Processing with Publishing",
                            True,
                            f"V2 processing completed with publishing integration in {processing_time:.2f}s - engine={engine}, job_id={job_id}",
                            {
                                "engine": engine,
                                "status": status,
                                "job_id": job_id,
                                "processing_time": processing_time,
                                "content_length": len(test_content)
                            }
                        )
                        return job_id
                    else:
                        self.log_test_result(
                            "V2 Text Processing with Publishing",
                            False,
                            f"V2 processing failed - engine={engine}, status={status}",
                            data
                        )
                        return None
                else:
                    error_text = await response.text()
                    self.log_test_result(
                        "V2 Text Processing with Publishing",
                        False,
                        f"Processing failed with status {response.status}: {error_text}",
                        {"status_code": response.status, "error": error_text}
                    )
                    return None
                    
        except Exception as e:
            self.log_test_result(
                "V2 Text Processing with Publishing",
                False,
                f"Processing error: {str(e)}",
                {"error": str(e)}
            )
            return None
    
    async def test_publishing_diagnostics_endpoints(self):
        """Test V2 publishing diagnostics endpoints"""
        try:
            # Test general publishing diagnostics
            print(f"ğŸ” Testing publishing diagnostics endpoints...")
            
            async with self.session.get(f"{self.backend_url}/api/publishing/diagnostics") as response:
                if response.status == 200:
                    data = await response.json()
                    total_runs = data.get('total_publishing_runs', 0)
                    successful_runs = data.get('successful_publishing_runs', 0)
                    failed_runs = data.get('failed_publishing_runs', 0)
                    blocked_runs = data.get('blocked_publishing_runs', 0)
                    publishing_results = data.get('publishing_results', [])
                    
                    self.log_test_result(
                        "Publishing Diagnostics General Endpoint",
                        True,
                        f"Publishing diagnostics retrieved - {total_runs} total runs, {successful_runs} successful, {failed_runs} failed, {blocked_runs} blocked",
                        {
                            "total_publishing_runs": total_runs,
                            "successful_publishing_runs": successful_runs,
                            "failed_publishing_runs": failed_runs,
                            "blocked_publishing_runs": blocked_runs,
                            "results_count": len(publishing_results)
                        }
                    )
                    
                    # Test specific publishing diagnostics if we have results
                    if publishing_results:
                        latest_result = publishing_results[0]
                        publishing_id = latest_result.get('publishing_id')
                        
                        if publishing_id:
                            await self.test_specific_publishing_diagnostics(publishing_id)
                    
                    return True
                else:
                    error_text = await response.text()
                    self.log_test_result(
                        "Publishing Diagnostics General Endpoint",
                        False,
                        f"Diagnostics failed with status {response.status}: {error_text}",
                        {"status_code": response.status, "error": error_text}
                    )
                    return False
                    
        except Exception as e:
            self.log_test_result(
                "Publishing Diagnostics General Endpoint",
                False,
                f"Diagnostics error: {str(e)}",
                {"error": str(e)}
            )
            return False
    
    async def test_specific_publishing_diagnostics(self, publishing_id: str):
        """Test specific publishing diagnostics endpoint"""
        try:
            print(f"ğŸ” Testing specific publishing diagnostics for {publishing_id}...")
            
            async with self.session.get(f"{self.backend_url}/api/publishing/diagnostics/{publishing_id}") as response:
                if response.status == 200:
                    data = await response.json()
                    publishing_status = data.get('publishing_status')
                    published_articles = data.get('published_articles', 0)
                    coverage_achieved = data.get('coverage_achieved', 0)
                    publishing_summary = data.get('publishing_summary', {})
                    
                    self.log_test_result(
                        "Publishing Diagnostics Specific Endpoint",
                        True,
                        f"Specific publishing diagnostics retrieved - Status: {publishing_status}, Articles: {published_articles}, Coverage: {coverage_achieved}%",
                        {
                            "publishing_id": publishing_id,
                            "publishing_status": publishing_status,
                            "published_articles": published_articles,
                            "coverage_achieved": coverage_achieved,
                            "publishing_summary": publishing_summary
                        }
                    )
                    return True
                elif response.status == 404:
                    self.log_test_result(
                        "Publishing Diagnostics Specific Endpoint",
                        False,
                        f"Publishing result not found: {publishing_id}",
                        {"publishing_id": publishing_id, "status_code": 404}
                    )
                    return False
                else:
                    error_text = await response.text()
                    self.log_test_result(
                        "Publishing Diagnostics Specific Endpoint",
                        False,
                        f"Specific diagnostics failed with status {response.status}: {error_text}",
                        {"status_code": response.status, "error": error_text}
                    )
                    return False
                    
        except Exception as e:
            self.log_test_result(
                "Publishing Diagnostics Specific Endpoint",
                False,
                f"Specific diagnostics error: {str(e)}",
                {"error": str(e)}
            )
            return False
    
    async def test_v2_only_content_validation(self):
        """Test V2-only content validation requirements"""
        try:
            print(f"ğŸ” Testing V2-only content validation...")
            
            # Get recent publishing results to analyze V2 validation
            async with self.session.get(f"{self.backend_url}/api/publishing/diagnostics") as response:
                if response.status == 200:
                    data = await response.json()
                    publishing_results = data.get('publishing_results', [])
                    
                    if not publishing_results:
                        self.log_test_result(
                            "V2-Only Content Validation",
                            False,
                            "No publishing results found to test V2 validation",
                            {"results_count": 0}
                        )
                        return False
                    
                    # Analyze V2 validation in recent results
                    v2_compliant_count = 0
                    total_results = len(publishing_results)
                    
                    for result in publishing_results:
                        v2_validation = result.get('v2_validation', {})
                        engine = result.get('engine')
                        
                        # Check V2 engine requirement
                        if engine == 'v2':
                            v2_compliant_count += 1
                        
                        # Check V2 validation details
                        v2_only_compliance = v2_validation.get('v2_only_compliance', False)
                        validation_success_rate = v2_validation.get('validation_success_rate', 0)
                        
                        if v2_only_compliance and validation_success_rate == 100.0:
                            print(f"   âœ… Result {result.get('publishing_id', 'unknown')} - V2 compliant with {validation_success_rate}% success rate")
                        else:
                            print(f"   âš ï¸ Result {result.get('publishing_id', 'unknown')} - V2 compliance: {v2_only_compliance}, Success rate: {validation_success_rate}%")
                    
                    v2_compliance_rate = (v2_compliant_count / total_results) * 100 if total_results > 0 else 0
                    
                    if v2_compliance_rate >= 80:  # Allow some tolerance for testing
                        self.log_test_result(
                            "V2-Only Content Validation",
                            True,
                            f"V2-only validation working - {v2_compliance_rate:.1f}% V2 compliance rate ({v2_compliant_count}/{total_results} results)",
                            {
                                "v2_compliant_count": v2_compliant_count,
                                "total_results": total_results,
                                "v2_compliance_rate": v2_compliance_rate
                            }
                        )
                        return True
                    else:
                        self.log_test_result(
                            "V2-Only Content Validation",
                            False,
                            f"V2-only validation insufficient - {v2_compliance_rate:.1f}% V2 compliance rate ({v2_compliant_count}/{total_results} results)",
                            {
                                "v2_compliant_count": v2_compliant_count,
                                "total_results": total_results,
                                "v2_compliance_rate": v2_compliance_rate
                            }
                        )
                        return False
                else:
                    self.log_test_result(
                        "V2-Only Content Validation",
                        False,
                        f"Failed to retrieve publishing results for validation test - status {response.status}",
                        {"status_code": response.status}
                    )
                    return False
                    
        except Exception as e:
            self.log_test_result(
                "V2-Only Content Validation",
                False,
                f"V2 validation test error: {str(e)}",
                {"error": str(e)}
            )
            return False
    
    async def test_coverage_requirement_verification(self):
        """Test 100% coverage requirement verification"""
        try:
            print(f"ğŸ“Š Testing 100% coverage requirement verification...")
            
            # Get recent publishing results to analyze coverage verification
            async with self.session.get(f"{self.backend_url}/api/publishing/diagnostics") as response:
                if response.status == 200:
                    data = await response.json()
                    publishing_results = data.get('publishing_results', [])
                    
                    if not publishing_results:
                        self.log_test_result(
                            "Coverage Requirement Verification",
                            False,
                            "No publishing results found to test coverage verification",
                            {"results_count": 0}
                        )
                        return False
                    
                    # Analyze coverage verification in recent results
                    coverage_compliant_count = 0
                    total_results = len(publishing_results)
                    coverage_sum = 0
                    
                    for result in publishing_results:
                        coverage_verification = result.get('coverage_verification', {})
                        coverage_achieved = result.get('coverage_achieved', 0)
                        
                        coverage_sum += coverage_achieved
                        
                        # Check coverage requirement (100%)
                        meets_requirement = coverage_verification.get('meets_requirement', False)
                        coverage_percent = coverage_verification.get('coverage_percent', 0)
                        
                        if meets_requirement and coverage_percent >= 100.0:
                            coverage_compliant_count += 1
                            print(f"   âœ… Result {result.get('publishing_id', 'unknown')} - Coverage: {coverage_percent}% (meets requirement)")
                        else:
                            print(f"   âš ï¸ Result {result.get('publishing_id', 'unknown')} - Coverage: {coverage_percent}% (requirement: {meets_requirement})")
                    
                    average_coverage = coverage_sum / total_results if total_results > 0 else 0
                    coverage_compliance_rate = (coverage_compliant_count / total_results) * 100 if total_results > 0 else 0
                    
                    if coverage_compliance_rate >= 70:  # Allow some tolerance for testing
                        self.log_test_result(
                            "Coverage Requirement Verification",
                            True,
                            f"Coverage verification working - {coverage_compliance_rate:.1f}% compliance rate, {average_coverage:.1f}% average coverage",
                            {
                                "coverage_compliant_count": coverage_compliant_count,
                                "total_results": total_results,
                                "coverage_compliance_rate": coverage_compliance_rate,
                                "average_coverage": average_coverage
                            }
                        )
                        return True
                    else:
                        self.log_test_result(
                            "Coverage Requirement Verification",
                            False,
                            f"Coverage verification insufficient - {coverage_compliance_rate:.1f}% compliance rate, {average_coverage:.1f}% average coverage",
                            {
                                "coverage_compliant_count": coverage_compliant_count,
                                "total_results": total_results,
                                "coverage_compliance_rate": coverage_compliance_rate,
                                "average_coverage": average_coverage
                            }
                        )
                        return False
                else:
                    self.log_test_result(
                        "Coverage Requirement Verification",
                        False,
                        f"Failed to retrieve publishing results for coverage test - status {response.status}",
                        {"status_code": response.status}
                    )
                    return False
                    
        except Exception as e:
            self.log_test_result(
                "Coverage Requirement Verification",
                False,
                f"Coverage verification test error: {str(e)}",
                {"error": str(e)}
            )
            return False
    
    async def test_content_library_structure_creation(self):
        """Test comprehensive content library structure creation"""
        try:
            print(f"ğŸ—ï¸ Testing content library structure creation...")
            
            # Get content library articles to verify structure
            async with self.session.get(f"{self.backend_url}/api/content-library") as response:
                if response.status == 200:
                    data = await response.json()
                    total_articles = data.get('total', 0)
                    articles = data.get('articles', [])
                    
                    if not articles:
                        self.log_test_result(
                            "Content Library Structure Creation",
                            False,
                            "No articles found in content library to test structure",
                            {"total_articles": total_articles}
                        )
                        return False
                    
                    # Analyze content library structure in recent articles
                    v2_articles = []
                    structure_compliant_count = 0
                    
                    for article in articles[:10]:  # Check recent 10 articles
                        # Check for V2 engine metadata
                        processing_metadata = article.get('processing_metadata', {})
                        engine = processing_metadata.get('engine') or article.get('engine')
                        
                        if engine == 'v2':
                            v2_articles.append(article)
                            
                            # Check required content library fields
                            required_fields = ['html', 'markdown', 'toc', 'faq', 'related_links', 'provenance_map', 'metrics', 'media_references']
                            present_fields = []
                            
                            for field in required_fields:
                                if field in article and article[field] is not None:
                                    present_fields.append(field)
                            
                            structure_compliance = len(present_fields) / len(required_fields) * 100
                            
                            if structure_compliance >= 70:  # Allow some tolerance
                                structure_compliant_count += 1
                                print(f"   âœ… Article {article.get('id', 'unknown')[:8]} - Structure: {structure_compliance:.1f}% ({len(present_fields)}/{len(required_fields)} fields)")
                            else:
                                print(f"   âš ï¸ Article {article.get('id', 'unknown')[:8]} - Structure: {structure_compliance:.1f}% ({len(present_fields)}/{len(required_fields)} fields)")
                    
                    if v2_articles:
                        structure_success_rate = (structure_compliant_count / len(v2_articles)) * 100
                        
                        if structure_success_rate >= 60:  # Allow tolerance for testing
                            self.log_test_result(
                                "Content Library Structure Creation",
                                True,
                                f"Content library structure creation working - {structure_success_rate:.1f}% compliance rate ({structure_compliant_count}/{len(v2_articles)} V2 articles)",
                                {
                                    "v2_articles_count": len(v2_articles),
                                    "structure_compliant_count": structure_compliant_count,
                                    "structure_success_rate": structure_success_rate,
                                    "total_articles": total_articles
                                }
                            )
                            return True
                        else:
                            self.log_test_result(
                                "Content Library Structure Creation",
                                False,
                                f"Content library structure insufficient - {structure_success_rate:.1f}% compliance rate ({structure_compliant_count}/{len(v2_articles)} V2 articles)",
                                {
                                    "v2_articles_count": len(v2_articles),
                                    "structure_compliant_count": structure_compliant_count,
                                    "structure_success_rate": structure_success_rate
                                }
                            )
                            return False
                    else:
                        self.log_test_result(
                            "Content Library Structure Creation",
                            False,
                            "No V2 articles found in content library to test structure",
                            {"total_articles": total_articles, "v2_articles_count": 0}
                        )
                        return False
                else:
                    self.log_test_result(
                        "Content Library Structure Creation",
                        False,
                        f"Failed to retrieve content library - status {response.status}",
                        {"status_code": response.status}
                    )
                    return False
                    
        except Exception as e:
            self.log_test_result(
                "Content Library Structure Creation",
                False,
                f"Content library structure test error: {str(e)}",
                {"error": str(e)}
            )
            return False
    
    async def test_publishing_result_storage(self):
        """Test publishing result storage in v2_publishing_results collection"""
        try:
            print(f"ğŸ’¾ Testing publishing result storage...")
            
            # Get publishing diagnostics to verify storage
            async with self.session.get(f"{self.backend_url}/api/publishing/diagnostics") as response:
                if response.status == 200:
                    data = await response.json()
                    total_runs = data.get('total_publishing_runs', 0)
                    publishing_results = data.get('publishing_results', [])
                    
                    if total_runs == 0:
                        self.log_test_result(
                            "Publishing Result Storage",
                            False,
                            "No publishing results found in storage",
                            {"total_publishing_runs": total_runs}
                        )
                        return False
                    
                    # Analyze storage completeness
                    complete_results_count = 0
                    v2_results_count = 0
                    
                    for result in publishing_results:
                        # Check for V2 engine
                        engine = result.get('engine')
                        if engine == 'v2':
                            v2_results_count += 1
                        
                        # Check for required storage fields
                        required_fields = ['publishing_id', 'run_id', 'publishing_status', 'timestamp']
                        has_all_fields = all(field in result for field in required_fields)
                        
                        if has_all_fields:
                            complete_results_count += 1
                            print(f"   âœ… Result {result.get('publishing_id', 'unknown')} - Complete storage (engine: {engine})")
                        else:
                            missing_fields = [field for field in required_fields if field not in result]
                            print(f"   âš ï¸ Result {result.get('publishing_id', 'unknown')} - Missing fields: {missing_fields}")
                    
                    storage_completeness = (complete_results_count / len(publishing_results)) * 100 if publishing_results else 0
                    v2_storage_rate = (v2_results_count / len(publishing_results)) * 100 if publishing_results else 0
                    
                    if storage_completeness >= 80 and v2_storage_rate >= 70:
                        self.log_test_result(
                            "Publishing Result Storage",
                            True,
                            f"Publishing result storage working - {storage_completeness:.1f}% complete, {v2_storage_rate:.1f}% V2 results",
                            {
                                "total_publishing_runs": total_runs,
                                "complete_results_count": complete_results_count,
                                "v2_results_count": v2_results_count,
                                "storage_completeness": storage_completeness,
                                "v2_storage_rate": v2_storage_rate
                            }
                        )
                        return True
                    else:
                        self.log_test_result(
                            "Publishing Result Storage",
                            False,
                            f"Publishing result storage insufficient - {storage_completeness:.1f}% complete, {v2_storage_rate:.1f}% V2 results",
                            {
                                "total_publishing_runs": total_runs,
                                "complete_results_count": complete_results_count,
                                "v2_results_count": v2_results_count,
                                "storage_completeness": storage_completeness,
                                "v2_storage_rate": v2_storage_rate
                            }
                        )
                        return False
                else:
                    self.log_test_result(
                        "Publishing Result Storage",
                        False,
                        f"Failed to retrieve publishing results for storage test - status {response.status}",
                        {"status_code": response.status}
                    )
                    return False
                    
        except Exception as e:
            self.log_test_result(
                "Publishing Result Storage",
                False,
                f"Publishing result storage test error: {str(e)}",
                {"error": str(e)}
            )
            return False
    
    async def test_republish_endpoint(self):
        """Test POST /api/publishing/republish endpoint"""
        try:
            print(f"ğŸ”„ Testing republish endpoint...")
            
            # Create a test run_id for republishing
            test_run_id = f"test_run_{int(datetime.utcnow().timestamp())}"
            
            # Test republish endpoint
            form_data = aiohttp.FormData()
            form_data.add_field('run_id', test_run_id)
            
            async with self.session.post(
                f"{self.backend_url}/api/publishing/republish",
                data=form_data
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    message = data.get('message')
                    publishing_status = data.get('publishing_status')
                    run_id = data.get('run_id')
                    
                    self.log_test_result(
                        "Republish Endpoint",
                        True,
                        f"Republish endpoint working - Status: {publishing_status}, Run ID: {run_id}",
                        {
                            "message": message,
                            "publishing_status": publishing_status,
                            "run_id": run_id,
                            "test_run_id": test_run_id
                        }
                    )
                    return True
                elif response.status == 404:
                    # Expected for test run_id that doesn't exist
                    self.log_test_result(
                        "Republish Endpoint",
                        True,
                        f"Republish endpoint working - Correctly returned 404 for non-existent run_id: {test_run_id}",
                        {"test_run_id": test_run_id, "status_code": 404}
                    )
                    return True
                else:
                    error_text = await response.text()
                    self.log_test_result(
                        "Republish Endpoint",
                        False,
                        f"Republish failed with status {response.status}: {error_text}",
                        {"status_code": response.status, "error": error_text}
                    )
                    return False
                    
        except Exception as e:
            self.log_test_result(
                "Republish Endpoint",
                False,
                f"Republish endpoint test error: {str(e)}",
                {"error": str(e)}
            )
            return False
    
    async def run_comprehensive_v2_step11_tests(self):
        """Run all V2 Engine Step 11 Publishing Flow tests"""
        print("ğŸš€ V2 ENGINE STEP 11 PUBLISHING FLOW (V2 ONLY) - COMPREHENSIVE TESTING STARTED")
        print("=" * 80)
        
        await self.setup_session()
        
        try:
            # Test sequence for V2 Step 11 Publishing Flow
            test_sequence = [
                ("V2 Engine Health Check", self.test_v2_engine_health_check),
                ("V2 Text Processing with Publishing", self.test_v2_text_processing_with_publishing),
                ("Publishing Diagnostics Endpoints", self.test_publishing_diagnostics_endpoints),
                ("V2-Only Content Validation", self.test_v2_only_content_validation),
                ("Coverage Requirement Verification", self.test_coverage_requirement_verification),
                ("Content Library Structure Creation", self.test_content_library_structure_creation),
                ("Publishing Result Storage", self.test_publishing_result_storage),
                ("Republish Endpoint", self.test_republish_endpoint)
            ]
            
            # Execute all tests
            for test_name, test_func in test_sequence:
                print(f"ğŸ§ª Running: {test_name}")
                await test_func()
                await asyncio.sleep(1)  # Brief pause between tests
            
        finally:
            await self.cleanup_session()
        
        # Calculate results
        total_tests = len(self.test_results)
        passed_tests = len([r for r in self.test_results if r['success']])
        failed_tests = total_tests - passed_tests
        success_rate = (passed_tests / total_tests) * 100 if total_tests > 0 else 0
        
        print("\n" + "=" * 80)
        print("ğŸ¯ V2 ENGINE STEP 11 PUBLISHING FLOW TESTING RESULTS")
        print("=" * 80)
        print(f"ğŸ“Š OVERALL RESULTS: {passed_tests}/{total_tests} tests passed ({success_rate:.1f}% success rate)")
        print(f"âœ… PASSED: {passed_tests}")
        print(f"âŒ FAILED: {failed_tests}")
        
        if success_rate >= 75:
            print(f"ğŸ‰ V2 ENGINE STEP 11 PUBLISHING FLOW: OPERATIONAL ({success_rate:.1f}% success rate)")
            print("âœ… V2-only publishing system is working with content validation, coverage verification, and content library persistence")
        else:
            print(f"âš ï¸ V2 ENGINE STEP 11 PUBLISHING FLOW: NEEDS ATTENTION ({success_rate:.1f}% success rate)")
            print("âŒ V2-only publishing system has issues that need to be addressed")
        
        # Show failed tests
        failed_test_results = [r for r in self.test_results if not r['success']]
        if failed_test_results:
            print(f"\nâŒ FAILED TESTS ({len(failed_test_results)}):")
            for result in failed_test_results:
                print(f"   â€¢ {result['test']}: {result['details']}")
        
        print("\n" + "=" * 80)
        return success_rate >= 75

async def main():
    """Main test execution"""
    tester = V2Step11PublishingTester()
    success = await tester.run_comprehensive_v2_step11_tests()
    return success

if __name__ == "__main__":
    asyncio.run(main())