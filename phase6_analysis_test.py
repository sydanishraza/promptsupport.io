#!/usr/bin/env python3
"""
PHASE 6 ENHANCED MULTI-DIMENSIONAL CONTENT PROCESSING PIPELINE ANALYSIS
Direct database analysis to verify Phase 6 features without API timeouts
"""

import os
import sys
import json
from datetime import datetime
from pymongo import MongoClient

def log_test_result(message, status="INFO"):
    """Log test results with timestamp"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] {status}: {message}")

def connect_to_database():
    """Connect to MongoDB database"""
    try:
        MONGO_URL = os.getenv("MONGO_URL", "mongodb://localhost:27017/")
        client = MongoClient(MONGO_URL)
        db = client.promptsupport_db
        
        # Test connection
        client.admin.command('ping')
        log_test_result("‚úÖ Database connection successful", "SUCCESS")
        return db
        
    except Exception as e:
        log_test_result(f"‚ùå Database connection failed: {e}", "ERROR")
        return None

def analyze_multi_dimensional_processing(db):
    """Analyze evidence of multi-dimensional content processing"""
    try:
        log_test_result("üß† ANALYZING MULTI-DIMENSIONAL PROCESSING EVIDENCE", "CRITICAL")
        
        # Get all articles from content library
        articles = list(db.content_library.find({}))
        total_articles = len(articles)
        
        log_test_result(f"üìö Total articles in database: {total_articles}")
        
        if total_articles == 0:
            log_test_result("‚ùå No articles found in database", "ERROR")
            return False
        
        # Analyze articles for multi-dimensional processing evidence
        evidence = {
            'outline_based_articles': 0,
            'enhanced_articles': 0,
            'different_content_types': set(),
            'different_article_types': set(),
            'articles_with_metadata': 0,
            'articles_with_tags': 0,
            'processing_approaches': set()
        }
        
        for article in articles:
            metadata = article.get('metadata', {})
            article_type = article.get('article_type', 'unknown')
            tags = article.get('tags', [])
            
            # Check for outline-based processing
            if metadata.get('outline_based'):
                evidence['outline_based_articles'] += 1
            
            # Check for enhanced processing indicators
            if any(key in metadata for key in ['enhancement_type', 'enhanced', 'processing_strategy']):
                evidence['enhanced_articles'] += 1
            
            # Track content and article types
            if 'content_type' in metadata:
                evidence['different_content_types'].add(metadata['content_type'])
            
            evidence['different_article_types'].add(article_type)
            
            # Check metadata presence
            if metadata and len(metadata) > 0:
                evidence['articles_with_metadata'] += 1
            
            # Check tags
            if tags and len(tags) > 0:
                evidence['articles_with_tags'] += 1
            
            # Check for processing approach indicators
            if 'processing_approach' in metadata:
                evidence['processing_approaches'].add(metadata['processing_approach'])
        
        # Evaluate evidence
        log_test_result("üìä Multi-dimensional processing analysis:")
        log_test_result(f"   üìã Outline-based articles: {evidence['outline_based_articles']}")
        log_test_result(f"   üîß Enhanced articles: {evidence['enhanced_articles']}")
        log_test_result(f"   üìù Content types: {list(evidence['different_content_types'])}")
        log_test_result(f"   üìÑ Article types: {list(evidence['different_article_types'])}")
        log_test_result(f"   üè∑Ô∏è Articles with metadata: {evidence['articles_with_metadata']}")
        log_test_result(f"   üîñ Articles with tags: {evidence['articles_with_tags']}")
        log_test_result(f"   ‚öôÔ∏è Processing approaches: {list(evidence['processing_approaches'])}")
        
        # Success criteria
        success_indicators = 0
        
        if evidence['outline_based_articles'] > 0:
            success_indicators += 1
            log_test_result("‚úÖ Outline-based processing detected")
        
        if len(evidence['different_article_types']) >= 3:
            success_indicators += 1
            log_test_result("‚úÖ Diverse article types detected")
        
        if evidence['articles_with_metadata'] > total_articles * 0.5:
            success_indicators += 1
            log_test_result("‚úÖ Rich metadata implementation detected")
        
        if evidence['enhanced_articles'] > 0:
            success_indicators += 1
            log_test_result("‚úÖ Enhanced processing detected")
        
        if len(evidence['processing_approaches']) > 0:
            success_indicators += 1
            log_test_result("‚úÖ Multiple processing approaches detected")
        
        success_rate = (success_indicators / 5) * 100
        
        if success_rate >= 60:
            log_test_result(f"‚úÖ Multi-dimensional processing PASSED ({success_rate:.1f}%)", "SUCCESS")
            return True
        else:
            log_test_result(f"‚ùå Multi-dimensional processing FAILED ({success_rate:.1f}%)", "ERROR")
            return False
            
    except Exception as e:
        log_test_result(f"‚ùå Multi-dimensional processing analysis failed: {e}", "ERROR")
        return False

def analyze_adaptive_granularity(db):
    """Analyze evidence of adaptive granularity processing"""
    try:
        log_test_result("üìè ANALYZING ADAPTIVE GRANULARITY EVIDENCE", "CRITICAL")
        
        # Group articles by source document
        pipeline = [
            {"$group": {
                "_id": "$source_document",
                "count": {"$sum": 1},
                "articles": {"$push": {"title": "$title", "article_type": "$article_type"}}
            }},
            {"$sort": {"count": -1}}
        ]
        
        source_groups = list(db.content_library.aggregate(pipeline))
        
        if not source_groups:
            log_test_result("‚ùå No source document groupings found", "ERROR")
            return False
        
        granularity_patterns = {
            'unified': 0,      # 1 article
            'shallow': 0,      # 2-3 articles
            'moderate': 0,     # 4-6 articles
            'deep': 0,         # 7+ articles
            'total_sources': len(source_groups)
        }
        
        log_test_result("üìä Granularity analysis by source document:")
        
        for group in source_groups[:10]:  # Show top 10
            source = group['_id'] or 'Unknown'
            count = group['count']
            
            if count == 1:
                granularity_patterns['unified'] += 1
                granularity_type = "Unified"
            elif 2 <= count <= 3:
                granularity_patterns['shallow'] += 1
                granularity_type = "Shallow"
            elif 4 <= count <= 6:
                granularity_patterns['moderate'] += 1
                granularity_type = "Moderate"
            else:
                granularity_patterns['deep'] += 1
                granularity_type = "Deep"
            
            log_test_result(f"   üìÑ {source}: {count} articles ({granularity_type})")
        
        # Evaluate granularity diversity
        granularity_types_found = sum([
            1 if granularity_patterns['unified'] > 0 else 0,
            1 if granularity_patterns['shallow'] > 0 else 0,
            1 if granularity_patterns['moderate'] > 0 else 0,
            1 if granularity_patterns['deep'] > 0 else 0
        ])
        
        log_test_result(f"üìà Granularity pattern summary:")
        log_test_result(f"   üîπ Unified (1 article): {granularity_patterns['unified']} sources")
        log_test_result(f"   üîπ Shallow (2-3 articles): {granularity_patterns['shallow']} sources")
        log_test_result(f"   üîπ Moderate (4-6 articles): {granularity_patterns['moderate']} sources")
        log_test_result(f"   üîπ Deep (7+ articles): {granularity_patterns['deep']} sources")
        log_test_result(f"   üìä Different granularity types: {granularity_types_found}/4")
        
        if granularity_types_found >= 2:
            log_test_result("‚úÖ Adaptive granularity PASSED - Multiple granularity patterns detected", "SUCCESS")
            return True
        else:
            log_test_result("‚ùå Adaptive granularity FAILED - Limited granularity diversity", "ERROR")
            return False
            
    except Exception as e:
        log_test_result(f"‚ùå Adaptive granularity analysis failed: {e}", "ERROR")
        return False

def analyze_enhanced_formatting(db):
    """Analyze evidence of enhanced formatting preservation"""
    try:
        log_test_result("üé® ANALYZING ENHANCED FORMATTING PRESERVATION", "CRITICAL")
        
        # Get recent articles to analyze formatting
        articles = list(db.content_library.find({}).sort("created_at", -1).limit(50))
        
        if not articles:
            log_test_result("‚ùå No articles found for formatting analysis", "ERROR")
            return False
        
        formatting_evidence = {
            'code_blocks': 0,
            'lists': 0,
            'tables': 0,
            'headings': 0,
            'rich_html': 0,
            'callouts': 0,
            'total_analyzed': len(articles)
        }
        
        for article in articles:
            content = article.get('content', '')
            
            # Check for code blocks
            if any(tag in content for tag in ['<pre>', '<code>', '```', 'language-']):
                formatting_evidence['code_blocks'] += 1
            
            # Check for lists
            if any(tag in content for tag in ['<ul>', '<ol>', '<li>']):
                formatting_evidence['lists'] += 1
            
            # Check for tables
            if any(tag in content for tag in ['<table>', '<tr>', '<td>', '<th>']):
                formatting_evidence['tables'] += 1
            
            # Check for proper headings
            if any(tag in content for tag in ['<h1>', '<h2>', '<h3>', '<h4>', '<h5>', '<h6>']):
                formatting_evidence['headings'] += 1
            
            # Check for rich HTML elements
            if any(tag in content for tag in ['<strong>', '<em>', '<div>', '<span>', '<blockquote>', '<figure>']):
                formatting_evidence['rich_html'] += 1
            
            # Check for callouts/notes
            if any(indicator in content.lower() for indicator in ['note:', 'tip:', 'warning:', 'important:', 'class="note"', 'class="tip"']):
                formatting_evidence['callouts'] += 1
        
        log_test_result("üìä Enhanced formatting analysis:")
        log_test_result(f"   üíª Code blocks: {formatting_evidence['code_blocks']} articles")
        log_test_result(f"   üìù Lists: {formatting_evidence['lists']} articles")
        log_test_result(f"   üìä Tables: {formatting_evidence['tables']} articles")
        log_test_result(f"   üìã Headings: {formatting_evidence['headings']} articles")
        log_test_result(f"   üé® Rich HTML: {formatting_evidence['rich_html']} articles")
        log_test_result(f"   üí° Callouts: {formatting_evidence['callouts']} articles")
        
        # Evaluate formatting preservation
        formatting_types = sum([
            1 if formatting_evidence['code_blocks'] > 0 else 0,
            1 if formatting_evidence['lists'] > 0 else 0,
            1 if formatting_evidence['tables'] > 0 else 0,
            1 if formatting_evidence['headings'] > 0 else 0,
            1 if formatting_evidence['rich_html'] > 0 else 0,
            1 if formatting_evidence['callouts'] > 0 else 0
        ])
        
        success_rate = (formatting_types / 6) * 100
        
        if success_rate >= 50:  # At least 3 out of 6 formatting types
            log_test_result(f"‚úÖ Enhanced formatting preservation PASSED ({success_rate:.1f}%)", "SUCCESS")
            return True
        else:
            log_test_result(f"‚ùå Enhanced formatting preservation FAILED ({success_rate:.1f}%)", "ERROR")
            return False
            
    except Exception as e:
        log_test_result(f"‚ùå Enhanced formatting analysis failed: {e}", "ERROR")
        return False

def analyze_pipeline_integration(db):
    """Analyze evidence of complete pipeline integration"""
    try:
        log_test_result("üîÑ ANALYZING PROCESSING PIPELINE INTEGRATION", "CRITICAL")
        
        # Get articles and analyze integration features
        articles = list(db.content_library.find({}))
        
        if not articles:
            log_test_result("‚ùå No articles found for pipeline analysis", "ERROR")
            return False
        
        integration_evidence = {
            'articles_with_metadata': 0,
            'articles_with_tags': 0,
            'articles_with_cross_references': 0,
            'articles_with_proper_status': 0,
            'articles_with_timestamps': 0,
            'articles_with_ids': 0,
            'faq_articles': 0,
            'overview_articles': 0,
            'total_articles': len(articles)
        }
        
        for article in articles:
            # Check metadata
            if article.get('metadata') and len(article.get('metadata', {})) > 0:
                integration_evidence['articles_with_metadata'] += 1
            
            # Check tags
            if article.get('tags') and len(article.get('tags', [])) > 0:
                integration_evidence['articles_with_tags'] += 1
            
            # Check cross-references in content
            content = article.get('content', '')
            if 'content-library/article' in content or 'related' in content.lower():
                integration_evidence['articles_with_cross_references'] += 1
            
            # Check proper status
            if article.get('status') in ['published', 'draft', 'training']:
                integration_evidence['articles_with_proper_status'] += 1
            
            # Check timestamps
            if article.get('created_at'):
                integration_evidence['articles_with_timestamps'] += 1
            
            # Check IDs
            if article.get('id') or article.get('_id'):
                integration_evidence['articles_with_ids'] += 1
            
            # Check for specific article types
            article_type = article.get('article_type', '')
            title = article.get('title', '').lower()
            
            if article_type == 'faq' or 'faq' in title or 'troubleshooting' in title:
                integration_evidence['faq_articles'] += 1
            
            if article_type == 'overview' or 'overview' in title:
                integration_evidence['overview_articles'] += 1
        
        log_test_result("üìä Pipeline integration analysis:")
        log_test_result(f"   üè∑Ô∏è Articles with metadata: {integration_evidence['articles_with_metadata']}")
        log_test_result(f"   üîñ Articles with tags: {integration_evidence['articles_with_tags']}")
        log_test_result(f"   üîó Articles with cross-references: {integration_evidence['articles_with_cross_references']}")
        log_test_result(f"   üìã Articles with proper status: {integration_evidence['articles_with_proper_status']}")
        log_test_result(f"   ‚è∞ Articles with timestamps: {integration_evidence['articles_with_timestamps']}")
        log_test_result(f"   üÜî Articles with IDs: {integration_evidence['articles_with_ids']}")
        log_test_result(f"   ‚ùì FAQ articles: {integration_evidence['faq_articles']}")
        log_test_result(f"   üìñ Overview articles: {integration_evidence['overview_articles']}")
        
        # Evaluate integration
        integration_score = 0
        max_score = 8
        
        if integration_evidence['articles_with_metadata'] > 0:
            integration_score += 1
        if integration_evidence['articles_with_tags'] > 0:
            integration_score += 1
        if integration_evidence['articles_with_cross_references'] > 0:
            integration_score += 1
        if integration_evidence['articles_with_proper_status'] > 0:
            integration_score += 1
        if integration_evidence['articles_with_timestamps'] > 0:
            integration_score += 1
        if integration_evidence['articles_with_ids'] > 0:
            integration_score += 1
        if integration_evidence['faq_articles'] > 0:
            integration_score += 1
        if integration_evidence['overview_articles'] > 0:
            integration_score += 1
        
        success_rate = (integration_score / max_score) * 100
        
        if success_rate >= 60:
            log_test_result(f"‚úÖ Processing pipeline integration PASSED ({success_rate:.1f}%)", "SUCCESS")
            return True
        else:
            log_test_result(f"‚ùå Processing pipeline integration FAILED ({success_rate:.1f}%)", "ERROR")
            return False
            
    except Exception as e:
        log_test_result(f"‚ùå Pipeline integration analysis failed: {e}", "ERROR")
        return False

def analyze_backward_compatibility(db):
    """Analyze backward compatibility by checking data consistency"""
    try:
        log_test_result("üîÑ ANALYZING BACKWARD COMPATIBILITY", "CRITICAL")
        
        # Check if basic article structure is maintained
        articles = list(db.content_library.find({}).limit(10))
        
        if not articles:
            log_test_result("‚ùå No articles found for compatibility analysis", "ERROR")
            return False
        
        compatibility_checks = {
            'basic_fields_present': 0,
            'content_accessible': 0,
            'titles_present': 0,
            'status_field_present': 0,
            'created_at_present': 0,
            'total_checked': len(articles)
        }
        
        required_fields = ['title', 'content', 'status', 'created_at']
        
        for article in articles:
            # Check basic fields
            if all(field in article for field in required_fields):
                compatibility_checks['basic_fields_present'] += 1
            
            # Check content accessibility
            if article.get('content') and len(article.get('content', '')) > 0:
                compatibility_checks['content_accessible'] += 1
            
            # Check individual fields
            if article.get('title'):
                compatibility_checks['titles_present'] += 1
            
            if article.get('status'):
                compatibility_checks['status_field_present'] += 1
            
            if article.get('created_at'):
                compatibility_checks['created_at_present'] += 1
        
        log_test_result("üìä Backward compatibility analysis:")
        log_test_result(f"   üìã Basic fields present: {compatibility_checks['basic_fields_present']}/{compatibility_checks['total_checked']}")
        log_test_result(f"   üìÑ Content accessible: {compatibility_checks['content_accessible']}/{compatibility_checks['total_checked']}")
        log_test_result(f"   üè∑Ô∏è Titles present: {compatibility_checks['titles_present']}/{compatibility_checks['total_checked']}")
        log_test_result(f"   üìä Status field present: {compatibility_checks['status_field_present']}/{compatibility_checks['total_checked']}")
        log_test_result(f"   ‚è∞ Created_at present: {compatibility_checks['created_at_present']}/{compatibility_checks['total_checked']}")
        
        # Calculate success rate
        total_checks = sum(compatibility_checks.values()) - compatibility_checks['total_checked']
        max_checks = compatibility_checks['total_checked'] * 5
        success_rate = (total_checks / max_checks) * 100
        
        if success_rate >= 80:
            log_test_result(f"‚úÖ Backward compatibility PASSED ({success_rate:.1f}%)", "SUCCESS")
            return True
        else:
            log_test_result(f"‚ùå Backward compatibility FAILED ({success_rate:.1f}%)", "ERROR")
            return False
            
    except Exception as e:
        log_test_result(f"‚ùå Backward compatibility analysis failed: {e}", "ERROR")
        return False

def analyze_error_handling_resilience(db):
    """Analyze system resilience by checking data quality and consistency"""
    try:
        log_test_result("üõ°Ô∏è ANALYZING ERROR HANDLING & RESILIENCE", "CRITICAL")
        
        # Check for data quality indicators
        articles = list(db.content_library.find({}))
        
        if not articles:
            log_test_result("‚ùå No articles found for resilience analysis", "ERROR")
            return False
        
        resilience_indicators = {
            'articles_with_content': 0,
            'articles_with_valid_ids': 0,
            'articles_without_errors': 0,
            'articles_with_reasonable_length': 0,
            'articles_with_valid_timestamps': 0,
            'total_articles': len(articles)
        }
        
        for article in articles:
            # Check content presence and quality
            content = article.get('content', '')
            if content and len(content) > 50:  # Reasonable content length
                resilience_indicators['articles_with_content'] += 1
            
            if len(content) > 100:  # More substantial content
                resilience_indicators['articles_with_reasonable_length'] += 1
            
            # Check valid IDs
            if article.get('id') or article.get('_id'):
                resilience_indicators['articles_with_valid_ids'] += 1
            
            # Check for error indicators in content
            if not any(error_word in content.lower() for error_word in ['error', 'failed', 'exception', 'null', 'undefined']):
                resilience_indicators['articles_without_errors'] += 1
            
            # Check valid timestamps
            if article.get('created_at'):
                resilience_indicators['articles_with_valid_timestamps'] += 1
        
        log_test_result("üìä Error handling & resilience analysis:")
        log_test_result(f"   üìÑ Articles with content: {resilience_indicators['articles_with_content']}/{resilience_indicators['total_articles']}")
        log_test_result(f"   üÜî Articles with valid IDs: {resilience_indicators['articles_with_valid_ids']}/{resilience_indicators['total_articles']}")
        log_test_result(f"   ‚úÖ Articles without errors: {resilience_indicators['articles_without_errors']}/{resilience_indicators['total_articles']}")
        log_test_result(f"   üìè Articles with reasonable length: {resilience_indicators['articles_with_reasonable_length']}/{resilience_indicators['total_articles']}")
        log_test_result(f"   ‚è∞ Articles with valid timestamps: {resilience_indicators['articles_with_valid_timestamps']}/{resilience_indicators['total_articles']}")
        
        # Calculate resilience score
        total_positive = sum([
            resilience_indicators['articles_with_content'],
            resilience_indicators['articles_with_valid_ids'],
            resilience_indicators['articles_without_errors'],
            resilience_indicators['articles_with_reasonable_length'],
            resilience_indicators['articles_with_valid_timestamps']
        ])
        max_possible = resilience_indicators['total_articles'] * 5
        success_rate = (total_positive / max_possible) * 100
        
        if success_rate >= 70:
            log_test_result(f"‚úÖ Error handling & resilience PASSED ({success_rate:.1f}%)", "SUCCESS")
            return True
        else:
            log_test_result(f"‚ùå Error handling & resilience FAILED ({success_rate:.1f}%)", "ERROR")
            return False
            
    except Exception as e:
        log_test_result(f"‚ùå Error handling & resilience analysis failed: {e}", "ERROR")
        return False

def run_phase6_database_analysis():
    """Run Phase 6 analysis using direct database access"""
    log_test_result("üöÄ STARTING PHASE 6 DATABASE ANALYSIS", "CRITICAL")
    log_test_result("=" * 80)
    
    # Connect to database
    db = connect_to_database()
    if not db:
        log_test_result("‚ùå Database connection failed - aborting analysis", "CRITICAL_ERROR")
        return {}
    
    test_results = {
        'multi_dimensional_analysis': False,
        'adaptive_granularity_processing': False,
        'enhanced_formatting_preservation': False,
        'processing_pipeline_integration': False,
        'backward_compatibility': False,
        'error_handling_resilience': False
    }
    
    # Test 1: Multi-Dimensional Analysis
    log_test_result("\nTEST 1: Multi-Dimensional Analysis Evidence")
    test_results['multi_dimensional_analysis'] = analyze_multi_dimensional_processing(db)
    
    # Test 2: Adaptive Granularity
    log_test_result("\nTEST 2: Adaptive Granularity Evidence")
    test_results['adaptive_granularity_processing'] = analyze_adaptive_granularity(db)
    
    # Test 3: Enhanced Formatting Preservation
    log_test_result("\nTEST 3: Enhanced Formatting Preservation")
    test_results['enhanced_formatting_preservation'] = analyze_enhanced_formatting(db)
    
    # Test 4: Processing Pipeline Integration
    log_test_result("\nTEST 4: Processing Pipeline Integration")
    test_results['processing_pipeline_integration'] = analyze_pipeline_integration(db)
    
    # Test 5: Backward Compatibility
    log_test_result("\nTEST 5: Backward Compatibility")
    test_results['backward_compatibility'] = analyze_backward_compatibility(db)
    
    # Test 6: Error Handling & Resilience
    log_test_result("\nTEST 6: Error Handling & Resilience")
    test_results['error_handling_resilience'] = analyze_error_handling_resilience(db)
    
    # Final Results Summary
    log_test_result("\n" + "=" * 80)
    log_test_result("üéØ PHASE 6 DATABASE ANALYSIS RESULTS", "CRITICAL")
    log_test_result("=" * 80)
    
    passed_tests = sum(test_results.values())
    total_tests = len(test_results)
    
    for test_name, result in test_results.items():
        status = "‚úÖ PASSED" if result else "‚ùå FAILED"
        log_test_result(f"{test_name.replace('_', ' ').title()}: {status}")
    
    success_rate = (passed_tests / total_tests) * 100
    log_test_result(f"\nOVERALL RESULT: {passed_tests}/{total_tests} tests passed ({success_rate:.1f}%)")
    
    if success_rate >= 80:
        log_test_result("üéâ PHASE 6 SUCCESS: Enhanced Multi-Dimensional Content Processing Pipeline is working!", "CRITICAL_SUCCESS")
        log_test_result("‚úÖ Database analysis confirms Phase 6 features are operational", "CRITICAL_SUCCESS")
    elif success_rate >= 60:
        log_test_result("‚ö†Ô∏è PHASE 6 PARTIAL SUCCESS: Most features working but some issues detected", "WARNING")
    else:
        log_test_result("‚ùå PHASE 6 FAILURE: Critical issues with Enhanced Multi-Dimensional Content Processing Pipeline", "CRITICAL_ERROR")
    
    return test_results

if __name__ == "__main__":
    print("Phase 6 Enhanced Multi-Dimensional Content Processing Pipeline - Database Analysis")
    print("=" * 80)
    
    results = run_phase6_database_analysis()
    
    # Exit with appropriate code
    success_rate = (sum(results.values()) / len(results)) * 100 if results else 0
    if success_rate >= 80:
        sys.exit(0)  # Success
    else:
        sys.exit(1)  # Failure