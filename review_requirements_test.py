#!/usr/bin/env python3
"""
Review Requirements Testing - Enhanced Knowledge Engine
Testing the specific improvements mentioned in the review request:

1. Enhanced content splitting logic for rich documents (6-15 articles instead of 2-4)
2. Increased content processing limits (25000 chars for multiple articles, 20000 for single)
3. More aggressive splitting thresholds for DOCX files
4. Improved HTML formatting with better Markdown conversion
5. Enhanced list processing (unordered and ordered lists)
6. Better image embedding as HTML format instead of Markdown
"""

import requests
import json
import os
import io
import time
import re
from dotenv import load_dotenv

# Load environment variables
load_dotenv('/app/frontend/.env')

# Get backend URL from environment
BACKEND_URL = os.environ.get('REACT_APP_BACKEND_URL', 'https://75e2f69d-4b6d-467e-9338-70ba63fa8c3f.preview.emergentagent.com') + '/api'

class ReviewRequirementsTest:
    def __init__(self):
        self.base_url = BACKEND_URL
        self.test_results = {}
        print(f"üß™ Testing Enhanced Knowledge Engine Review Requirements")
        print(f"Backend URL: {self.base_url}")
        print("=" * 80)
        
    def create_comprehensive_multi_chapter_document(self):
        """Create a complex multi-chapter document for testing enhanced splitting"""
        return """# Comprehensive Enterprise Software Development Guide

## Table of Contents
1. Software Architecture Fundamentals
2. Database Design and Management
3. API Development and Integration
4. Security Implementation
5. Testing Strategies and Quality Assurance
6. DevOps and Deployment
7. Performance Optimization
8. Monitoring and Maintenance
9. Team Management and Collaboration
10. Project Planning and Execution
11. Documentation and Knowledge Management
12. Compliance and Regulatory Requirements

## Chapter 1: Software Architecture Fundamentals

Software architecture forms the backbone of any successful enterprise application. This chapter explores the fundamental principles and patterns that guide architectural decisions.

### Architectural Patterns

Modern software architecture relies on several key patterns:

- **Microservices Architecture**: Decomposing applications into small, independent services
- **Event-Driven Architecture**: Using events to trigger and communicate between services
- **Layered Architecture**: Organizing code into distinct layers with specific responsibilities
- **Domain-Driven Design**: Aligning software structure with business domains

### Design Principles

Key design principles include:

1. **Single Responsibility Principle**: Each component should have one reason to change
2. **Open/Closed Principle**: Software entities should be open for extension, closed for modification
3. **Dependency Inversion**: Depend on abstractions, not concretions
4. **Separation of Concerns**: Divide program functionality into distinct features

### Technology Stack Considerations

When selecting technologies, consider:
- Scalability requirements
- Team expertise
- Maintenance overhead
- Integration capabilities
- Performance characteristics

## Chapter 2: Database Design and Management

Database design is crucial for application performance and maintainability. This chapter covers relational and NoSQL database design principles.

### Relational Database Design

Key concepts in relational database design:

1. **Normalization**: Organizing data to reduce redundancy
2. **Entity-Relationship Modeling**: Defining relationships between data entities
3. **Indexing Strategies**: Optimizing query performance
4. **Constraint Management**: Ensuring data integrity

### NoSQL Database Patterns

NoSQL databases offer different approaches:

- **Document Stores**: MongoDB, CouchDB for flexible schema
- **Key-Value Stores**: Redis, DynamoDB for simple lookups
- **Column Families**: Cassandra, HBase for wide-column data
- **Graph Databases**: Neo4j, Amazon Neptune for relationship-heavy data

### Data Migration Strategies

Effective data migration requires:
1. Comprehensive data mapping
2. Validation procedures
3. Rollback mechanisms
4. Performance monitoring
5. Incremental migration approaches

## Chapter 3: API Development and Integration

APIs serve as the communication layer between different system components. This chapter covers RESTful API design and integration patterns.

### RESTful API Design

Best practices for REST APIs:

- **Resource-Based URLs**: Use nouns, not verbs in endpoints
- **HTTP Methods**: GET, POST, PUT, DELETE for different operations
- **Status Codes**: Appropriate HTTP status codes for responses
- **Versioning**: Maintain backward compatibility

### API Security

Security considerations include:

1. **Authentication**: Verifying user identity
2. **Authorization**: Controlling access to resources
3. **Rate Limiting**: Preventing abuse and overload
4. **Input Validation**: Sanitizing and validating all inputs
5. **HTTPS**: Encrypting data in transit

### Integration Patterns

Common integration patterns:
- **Synchronous Communication**: Direct API calls
- **Asynchronous Messaging**: Message queues and event streams
- **Batch Processing**: Scheduled data synchronization
- **Webhook Integration**: Event-driven notifications

## Chapter 4: Security Implementation

Security must be built into every layer of the application. This chapter covers comprehensive security strategies.

### Authentication and Authorization

Implementing robust access control:

- **Multi-Factor Authentication**: Adding extra security layers
- **Role-Based Access Control**: Defining user permissions
- **OAuth 2.0**: Secure authorization framework
- **JWT Tokens**: Stateless authentication tokens

### Data Protection

Protecting sensitive data:

1. **Encryption at Rest**: Securing stored data
2. **Encryption in Transit**: Protecting data transmission
3. **Key Management**: Secure handling of encryption keys
4. **Data Masking**: Hiding sensitive information in non-production environments

### Vulnerability Management

Ongoing security practices:
- Regular security audits
- Penetration testing
- Dependency scanning
- Security monitoring and alerting

## Chapter 5: Testing Strategies and Quality Assurance

Comprehensive testing ensures application reliability and maintainability. This chapter covers testing methodologies and tools.

### Testing Pyramid

The testing pyramid includes:

- **Unit Tests**: Testing individual components
- **Integration Tests**: Testing component interactions
- **End-to-End Tests**: Testing complete user workflows
- **Performance Tests**: Validating system performance

### Test-Driven Development

TDD process:

1. **Write Failing Test**: Define expected behavior
2. **Write Minimal Code**: Make the test pass
3. **Refactor**: Improve code quality
4. **Repeat**: Continue the cycle

### Quality Metrics

Important quality metrics:
- Code coverage percentage
- Defect density
- Mean time to resolution
- Customer satisfaction scores

## Chapter 6: DevOps and Deployment

DevOps practices streamline development and deployment processes. This chapter covers CI/CD pipelines and infrastructure management.

### Continuous Integration/Continuous Deployment

CI/CD pipeline components:

- **Source Control**: Version management with Git
- **Build Automation**: Automated compilation and packaging
- **Testing Automation**: Automated test execution
- **Deployment Automation**: Streamlined release processes

### Infrastructure as Code

Managing infrastructure through code:

1. **Configuration Management**: Ansible, Chef, Puppet
2. **Container Orchestration**: Kubernetes, Docker Swarm
3. **Cloud Provisioning**: Terraform, CloudFormation
4. **Monitoring and Logging**: Centralized observability

### Deployment Strategies

Different deployment approaches:
- Blue-green deployments
- Canary releases
- Rolling updates
- Feature flags

## Chapter 7: Performance Optimization

Performance optimization ensures applications meet user expectations and scale effectively.

### Performance Monitoring

Key performance indicators:

- **Response Time**: How quickly requests are processed
- **Throughput**: Number of requests handled per second
- **Resource Utilization**: CPU, memory, and disk usage
- **Error Rates**: Frequency of failed requests

### Optimization Techniques

Common optimization strategies:

1. **Caching**: Storing frequently accessed data
2. **Database Optimization**: Query tuning and indexing
3. **Code Optimization**: Algorithmic improvements
4. **Load Balancing**: Distributing traffic across servers
5. **Content Delivery Networks**: Geographic content distribution

### Scalability Patterns

Scaling approaches:
- Horizontal scaling (scale out)
- Vertical scaling (scale up)
- Auto-scaling based on demand
- Microservices decomposition

## Chapter 8: Monitoring and Maintenance

Ongoing monitoring and maintenance ensure system reliability and performance.

### Monitoring Strategy

Comprehensive monitoring includes:

- **Application Performance Monitoring**: APM tools
- **Infrastructure Monitoring**: Server and network metrics
- **Log Management**: Centralized logging and analysis
- **User Experience Monitoring**: Real user monitoring

### Maintenance Procedures

Regular maintenance tasks:

1. **Security Updates**: Applying patches and updates
2. **Performance Tuning**: Optimizing based on metrics
3. **Capacity Planning**: Preparing for growth
4. **Backup Verification**: Ensuring data recovery capabilities
5. **Documentation Updates**: Keeping documentation current

### Incident Response

Effective incident management:
- Clear escalation procedures
- Communication protocols
- Root cause analysis
- Post-incident reviews

## Chapter 9: Team Management and Collaboration

Successful software development requires effective team collaboration and management practices.

### Agile Methodologies

Popular agile frameworks:

- **Scrum**: Sprint-based development cycles
- **Kanban**: Continuous flow management
- **Extreme Programming**: Engineering practices focus
- **Scaled Agile**: Enterprise-level agile implementation

### Communication Tools

Essential collaboration tools:

1. **Project Management**: Jira, Trello, Asana
2. **Communication**: Slack, Microsoft Teams
3. **Documentation**: Confluence, Notion
4. **Code Review**: GitHub, GitLab, Bitbucket
5. **Video Conferencing**: Zoom, Google Meet

### Team Structure

Effective team organization:
- Cross-functional teams
- Clear roles and responsibilities
- Regular retrospectives
- Knowledge sharing sessions

## Chapter 10: Project Planning and Execution

Successful project delivery requires careful planning and execution management.

### Project Planning

Key planning activities:

- **Requirements Gathering**: Understanding stakeholder needs
- **Scope Definition**: Clearly defining project boundaries
- **Resource Allocation**: Assigning team members and tools
- **Timeline Development**: Creating realistic schedules

### Risk Management

Managing project risks:

1. **Risk Identification**: Cataloging potential issues
2. **Risk Assessment**: Evaluating probability and impact
3. **Mitigation Strategies**: Developing response plans
4. **Monitoring**: Tracking risk indicators
5. **Contingency Planning**: Preparing backup approaches

### Stakeholder Management

Effective stakeholder engagement:
- Regular communication
- Expectation management
- Feedback incorporation
- Change management

## Chapter 11: Documentation and Knowledge Management

Comprehensive documentation ensures knowledge preservation and team efficiency.

### Documentation Types

Essential documentation includes:

- **Technical Specifications**: Detailed system descriptions
- **API Documentation**: Interface specifications
- **User Guides**: End-user instructions
- **Operational Procedures**: Maintenance and support guides

### Knowledge Management

Effective knowledge sharing:

1. **Documentation Standards**: Consistent formatting and structure
2. **Version Control**: Managing document changes
3. **Search Capabilities**: Easy information retrieval
4. **Regular Updates**: Keeping information current
5. **Training Programs**: Onboarding and skill development

### Documentation Tools

Popular documentation platforms:
- GitBook for technical documentation
- Confluence for team collaboration
- Swagger for API documentation
- README files for code repositories

## Chapter 12: Compliance and Regulatory Requirements

Modern applications must comply with various regulations and standards.

### Regulatory Frameworks

Common compliance requirements:

- **GDPR**: European data protection regulation
- **HIPAA**: Healthcare information privacy
- **SOX**: Financial reporting requirements
- **PCI DSS**: Payment card industry standards

### Compliance Implementation

Achieving compliance requires:

1. **Gap Analysis**: Identifying compliance gaps
2. **Policy Development**: Creating governance policies
3. **Technical Controls**: Implementing security measures
4. **Audit Procedures**: Regular compliance assessments
5. **Training Programs**: Staff education on requirements

### Audit and Reporting

Compliance monitoring:
- Regular internal audits
- External compliance assessments
- Automated compliance monitoring
- Detailed reporting procedures

## Conclusion

This comprehensive guide covers the essential aspects of enterprise software development. Success requires balancing technical excellence with business requirements, team collaboration, and regulatory compliance.

### Key Success Factors

Critical elements for success:
- Strong architectural foundation
- Comprehensive testing strategy
- Effective team collaboration
- Continuous monitoring and improvement
- Regulatory compliance awareness

### Future Considerations

Emerging trends to watch:
- Artificial intelligence integration
- Serverless computing adoption
- Edge computing deployment
- Quantum computing preparation
- Sustainability considerations

The software development landscape continues to evolve, requiring continuous learning and adaptation to new technologies and methodologies."""

    def test_1_rich_document_processing(self):
        """Test 1: Rich Document Processing - Multiple articles from comprehensive content"""
        print("\nüîç TEST 1: Rich Document Processing")
        print("Testing: Enhanced content splitting logic for rich documents (6-15 articles instead of 2-4)")
        
        try:
            # Get initial Content Library count
            response = requests.get(f"{self.base_url}/content-library", timeout=10)
            initial_count = 0
            if response.status_code == 200:
                initial_count = response.json().get('total', 0)
                print(f"üìä Initial Content Library articles: {initial_count}")
            
            # Create and upload comprehensive document
            comprehensive_doc = self.create_comprehensive_multi_chapter_document()
            print(f"üìÑ Document length: {len(comprehensive_doc)} characters")
            print(f"üìÑ Chapters: {comprehensive_doc.count('## Chapter')}")
            
            file_data = io.BytesIO(comprehensive_doc.encode('utf-8'))
            files = {
                'file': ('enterprise_software_guide.txt', file_data, 'text/plain')
            }
            
            form_data = {
                'metadata': json.dumps({
                    "source": "review_requirements_test",
                    "test_type": "rich_document_processing",
                    "document_type": "comprehensive_enterprise_guide",
                    "original_filename": "enterprise_software_guide.txt"
                })
            }
            
            print("üì§ Uploading comprehensive enterprise guide...")
            response = requests.post(
                f"{self.base_url}/content/upload",
                files=files,
                data=form_data,
                timeout=120  # Extended timeout for large document
            )
            
            if response.status_code != 200:
                print(f"‚ùå Upload failed - status code {response.status_code}")
                print(f"Response: {response.text}")
                self.test_results['rich_document_processing'] = False
                return False
            
            upload_data = response.json()
            print(f"‚úÖ Upload successful")
            print(f"üìä Extracted content: {upload_data.get('extracted_content_length', 0)} characters")
            print(f"üìä Chunks created: {upload_data.get('chunks_created', 0)}")
            
            # Wait for AI processing
            print("‚è≥ Waiting for AI processing (15 seconds)...")
            time.sleep(15)
            
            # Check Content Library for new articles
            response = requests.get(f"{self.base_url}/content-library", timeout=15)
            if response.status_code != 200:
                print(f"‚ùå Could not check Content Library")
                self.test_results['rich_document_processing'] = False
                return False
            
            data = response.json()
            new_count = data.get('total', 0)
            articles = data.get('articles', [])
            
            articles_created = new_count - initial_count
            print(f"üìä Articles created: {articles_created} (was {initial_count}, now {new_count})")
            
            # Find articles related to our test
            enterprise_articles = [a for a in articles if 
                                 'enterprise' in a.get('title', '').lower() or
                                 'software' in a.get('title', '').lower() or
                                 'development' in a.get('title', '').lower() or
                                 'architecture' in a.get('title', '').lower()][:10]
            
            print(f"üìã Enterprise-related articles found: {len(enterprise_articles)}")
            for i, article in enumerate(enterprise_articles[:5], 1):
                title = article.get('title', 'Untitled')[:60]
                content_length = len(article.get('content', ''))
                print(f"  {i}. '{title}' ({content_length} chars)")
            
            # Evaluate results
            if articles_created >= 6:
                print(f"‚úÖ EXCELLENT: Created {articles_created} articles (target: 6-15)")
                self.test_results['rich_document_processing'] = True
                return True
            elif articles_created >= 3:
                print(f"‚ö†Ô∏è GOOD: Created {articles_created} articles (target: 6-15, acceptable: 3+)")
                self.test_results['rich_document_processing'] = True
                return True
            else:
                print(f"‚ùå INSUFFICIENT: Only created {articles_created} articles (target: 6-15)")
                self.test_results['rich_document_processing'] = False
                return False
                
        except Exception as e:
            print(f"‚ùå Rich document processing test failed - {str(e)}")
            self.test_results['rich_document_processing'] = False
            return False

    def test_2_html_formatting_verification(self):
        """Test 2: HTML Formatting - Verify proper HTML instead of Markdown"""
        print("\nüîç TEST 2: HTML Formatting Verification")
        print("Testing: Improved HTML formatting with better Markdown conversion")
        
        try:
            # Get recent articles from Content Library
            response = requests.get(f"{self.base_url}/content-library", timeout=15)
            if response.status_code != 200:
                print(f"‚ùå Could not fetch Content Library")
                self.test_results['html_formatting'] = False
                return False
            
            data = response.json()
            articles = data.get('articles', [])
            
            if not articles:
                print("‚ùå No articles found to analyze")
                self.test_results['html_formatting'] = False
                return False
            
            print(f"üìä Analyzing HTML formatting in {len(articles)} articles...")
            
            # Define HTML tags and Markdown patterns to look for
            html_tags = ['<h1>', '<h2>', '<h3>', '<h4>', '<p>', '<ul>', '<ol>', '<li>', 
                        '<strong>', '<em>', '<img>', '<blockquote>', '<pre>', '<code>']
            markdown_patterns = ['##', '**', '- ', '1. ', '```', '---', '![', '](', '*', '_']
            
            articles_analyzed = 0
            total_html_tags = 0
            total_markdown_patterns = 0
            articles_with_html = 0
            articles_with_markdown = 0
            
            for article in articles[:20]:  # Analyze first 20 articles
                content = article.get('content', '')
                if not content or len(content) < 100:
                    continue
                
                articles_analyzed += 1
                
                # Count HTML tags
                html_count = sum(content.count(tag) for tag in html_tags)
                # Count Markdown patterns
                markdown_count = sum(content.count(pattern) for pattern in markdown_patterns)
                
                if html_count > 0:
                    articles_with_html += 1
                    total_html_tags += html_count
                
                if markdown_count > 0:
                    articles_with_markdown += 1
                    total_markdown_patterns += markdown_count
                
                # Show details for first few articles
                if articles_analyzed <= 3:
                    title = article.get('title', 'Untitled')[:40]
                    print(f"  üìÑ '{title}': HTML={html_count}, Markdown={markdown_count}")
            
            print(f"\nüìä HTML FORMATTING ANALYSIS:")
            print(f"   Articles analyzed: {articles_analyzed}")
            print(f"   Articles with HTML tags: {articles_with_html}")
            print(f"   Articles with Markdown patterns: {articles_with_markdown}")
            print(f"   Total HTML tags: {total_html_tags}")
            print(f"   Total Markdown patterns: {total_markdown_patterns}")
            
            # Calculate HTML dominance
            if total_html_tags + total_markdown_patterns > 0:
                html_percentage = (total_html_tags / (total_html_tags + total_markdown_patterns)) * 100
                print(f"   HTML dominance: {html_percentage:.1f}%")
                
                if html_percentage >= 75:
                    print(f"‚úÖ EXCELLENT: Articles predominantly use HTML formatting")
                    self.test_results['html_formatting'] = True
                    return True
                elif html_percentage >= 50:
                    print(f"‚ö†Ô∏è GOOD: HTML formatting is improving but mixed with Markdown")
                    self.test_results['html_formatting'] = True
                    return True
                else:
                    print(f"‚ùå NEEDS IMPROVEMENT: Still predominantly Markdown formatting")
                    self.test_results['html_formatting'] = False
                    return False
            else:
                print("‚ùå No formatting detected in articles")
                self.test_results['html_formatting'] = False
                return False
                
        except Exception as e:
            print(f"‚ùå HTML formatting test failed - {str(e)}")
            self.test_results['html_formatting'] = False
            return False

    def test_3_enhanced_list_processing(self):
        """Test 3: Enhanced List Processing - Verify HTML lists instead of Markdown"""
        print("\nüîç TEST 3: Enhanced List Processing")
        print("Testing: Enhanced list processing (unordered and ordered lists)")
        
        try:
            # Create test document with various list formats
            list_test_content = """# Enhanced List Processing Test

This document tests the enhanced list processing capabilities.

## Unordered Lists

Key features of the enhanced system:
- Enhanced content splitting logic for rich documents
- Increased content processing limits (25000 chars for multiple articles)
- More aggressive splitting thresholds for DOCX files
- Improved HTML formatting with better Markdown conversion
- Enhanced list processing for unordered and ordered lists
- Better image embedding as HTML format instead of Markdown

Additional improvements:
* Better performance optimization
* Enhanced error handling
* Improved user experience
* Advanced analytics capabilities

## Ordered Lists

Implementation steps:
1. Install required dependencies and configure environment
2. Set up database connections and initialize schemas
3. Configure API endpoints and authentication mechanisms
4. Implement content processing pipelines
5. Deploy monitoring and logging systems
6. Perform comprehensive testing and validation
7. Document procedures and train team members

Quality assurance checklist:
1. Unit test coverage verification
2. Integration test execution
3. Performance benchmark validation
4. Security audit completion
5. User acceptance testing
6. Documentation review and approval

## Mixed Content Examples

Project phases include:
- Phase 1: Planning and requirements gathering
  1. Stakeholder interviews
  2. Requirements documentation
  3. Technical specification creation
- Phase 2: Development and implementation
  1. Core system development
  2. Feature implementation
  3. Testing and validation
- Phase 3: Deployment and maintenance
  1. Production deployment
  2. Monitoring setup
  3. Ongoing maintenance procedures"""

            # Upload the list test document
            file_data = io.BytesIO(list_test_content.encode('utf-8'))
            files = {
                'file': ('list_processing_test.txt', file_data, 'text/plain')
            }
            
            form_data = {
                'metadata': json.dumps({
                    "source": "review_requirements_test",
                    "test_type": "enhanced_list_processing",
                    "document_type": "list_processing_test",
                    "original_filename": "list_processing_test.txt"
                })
            }
            
            print("üì§ Uploading list processing test document...")
            response = requests.post(
                f"{self.base_url}/content/upload",
                files=files,
                data=form_data,
                timeout=60
            )
            
            if response.status_code != 200:
                print(f"‚ùå List test upload failed")
                self.test_results['enhanced_list_processing'] = False
                return False
            
            # Wait for processing
            print("‚è≥ Waiting for processing...")
            time.sleep(8)
            
            # Get processed articles
            response = requests.get(f"{self.base_url}/content-library", timeout=15)
            if response.status_code != 200:
                print(f"‚ùå Could not fetch processed articles")
                self.test_results['enhanced_list_processing'] = False
                return False
            
            data = response.json()
            articles = data.get('articles', [])
            
            # Find articles with list content
            list_articles = [a for a in articles if 
                           'list' in a.get('title', '').lower() or
                           'processing' in a.get('title', '').lower() or
                           'enhanced' in a.get('title', '').lower()][:5]
            
            if not list_articles:
                print("‚ö†Ô∏è Using recent articles for list analysis")
                list_articles = articles[:3]
            
            print(f"üìä Analyzing list processing in {len(list_articles)} articles...")
            
            html_lists_found = 0
            markdown_lists_found = 0
            total_html_list_items = 0
            total_markdown_list_items = 0
            
            for article in list_articles:
                content = article.get('content', '')
                if not content:
                    continue
                
                title = article.get('title', 'Untitled')[:40]
                
                # Count HTML list elements
                ul_count = content.count('<ul>')
                ol_count = content.count('<ol>')
                li_count = content.count('<li>')
                
                # Count Markdown list patterns
                dash_lists = len(re.findall(r'^- ', content, re.MULTILINE))
                asterisk_lists = len(re.findall(r'^\* ', content, re.MULTILINE))
                numbered_lists = len(re.findall(r'^\d+\. ', content, re.MULTILINE))
                
                html_list_total = ul_count + ol_count + li_count
                markdown_list_total = dash_lists + asterisk_lists + numbered_lists
                
                if html_list_total > 0:
                    html_lists_found += 1
                    total_html_list_items += html_list_total
                
                if markdown_list_total > 0:
                    markdown_lists_found += 1
                    total_markdown_list_items += markdown_list_total
                
                print(f"  üìÑ '{title}':")
                print(f"      HTML: <ul>={ul_count}, <ol>={ol_count}, <li>={li_count}")
                print(f"      Markdown: dash={dash_lists}, asterisk={asterisk_lists}, numbered={numbered_lists}")
            
            print(f"\nüìä LIST PROCESSING ANALYSIS:")
            print(f"   Articles with HTML lists: {html_lists_found}")
            print(f"   Articles with Markdown lists: {markdown_lists_found}")
            print(f"   Total HTML list elements: {total_html_list_items}")
            print(f"   Total Markdown list elements: {total_markdown_list_items}")
            
            # Evaluate results
            if total_html_list_items > total_markdown_list_items and html_lists_found > 0:
                print(f"‚úÖ EXCELLENT: HTML list processing is working correctly")
                self.test_results['enhanced_list_processing'] = True
                return True
            elif total_html_list_items > 0:
                print(f"‚ö†Ô∏è GOOD: Some HTML lists found, but improvement needed")
                self.test_results['enhanced_list_processing'] = True
                return True
            else:
                print(f"‚ùå NEEDS IMPROVEMENT: No HTML lists found")
                self.test_results['enhanced_list_processing'] = False
                return False
                
        except Exception as e:
            print(f"‚ùå Enhanced list processing test failed - {str(e)}")
            self.test_results['enhanced_list_processing'] = False
            return False

    def test_4_image_embedding_html_format(self):
        """Test 4: Image Embedding - Verify HTML format instead of Markdown"""
        print("\nüîç TEST 4: Image Embedding HTML Format")
        print("Testing: Better image embedding as HTML format instead of Markdown")
        
        try:
            # Get articles from Content Library
            response = requests.get(f"{self.base_url}/content-library", timeout=15)
            if response.status_code != 200:
                print(f"‚ùå Could not fetch Content Library")
                self.test_results['image_embedding_html'] = False
                return False
            
            data = response.json()
            articles = data.get('articles', [])
            
            print(f"üìä Analyzing image embedding in {len(articles)} articles...")
            
            articles_with_images = 0
            html_images = 0
            markdown_images = 0
            articles_analyzed = 0
            
            for article in articles:
                content = article.get('content', '')
                if not content or len(content) < 100:
                    continue
                
                articles_analyzed += 1
                
                # Check for HTML image tags
                html_img_pattern = r'<img[^>]+src=["\']([^"\']+)["\'][^>]*>'
                html_img_matches = re.findall(html_img_pattern, content, re.IGNORECASE)
                
                # Check for Markdown image syntax
                markdown_img_pattern = r'!\[([^\]]*)\]\(([^)]+)\)'
                markdown_img_matches = re.findall(markdown_img_pattern, content)
                
                if html_img_matches or markdown_img_matches:
                    articles_with_images += 1
                    title = article.get('title', 'Untitled')[:40]
                    
                    if html_img_matches:
                        html_images += len(html_img_matches)
                        print(f"  üìÑ '{title}': {len(html_img_matches)} HTML images")
                        
                        # Check for proper styling
                        for img_src in html_img_matches[:1]:  # Show first image
                            if 'style=' in content and 'max-width' in content:
                                print(f"      ‚úÖ HTML image with proper styling")
                            else:
                                print(f"      ‚ö†Ô∏è HTML image without optimal styling")
                    
                    if markdown_img_matches:
                        markdown_images += len(markdown_img_matches)
                        print(f"  üìÑ '{title}': {len(markdown_img_matches)} Markdown images")
                
                # Stop after analyzing enough articles with images
                if articles_with_images >= 10:
                    break
            
            print(f"\nüìä IMAGE EMBEDDING ANALYSIS:")
            print(f"   Articles analyzed: {articles_analyzed}")
            print(f"   Articles with images: {articles_with_images}")
            print(f"   HTML images found: {html_images}")
            print(f"   Markdown images found: {markdown_images}")
            
            # Evaluate results
            if html_images > 0 and markdown_images == 0:
                print(f"‚úÖ EXCELLENT: All images use HTML format")
                self.test_results['image_embedding_html'] = True
                return True
            elif html_images > markdown_images and html_images > 0:
                print(f"‚ö†Ô∏è GOOD: Predominantly HTML images, some Markdown remaining")
                self.test_results['image_embedding_html'] = True
                return True
            elif html_images > 0:
                print(f"‚ö†Ô∏è PARTIAL: Mixed image formats detected")
                self.test_results['image_embedding_html'] = True
                return True
            elif articles_with_images == 0:
                print(f"‚ÑπÔ∏è NO IMAGES: No articles with images found to test")
                self.test_results['image_embedding_html'] = True  # Not a failure if no images
                return True
            else:
                print(f"‚ùå NEEDS IMPROVEMENT: No HTML images found")
                self.test_results['image_embedding_html'] = False
                return False
                
        except Exception as e:
            print(f"‚ùå Image embedding test failed - {str(e)}")
            self.test_results['image_embedding_html'] = False
            return False

    def test_5_content_processing_limits(self):
        """Test 5: Content Processing Limits - Verify increased processing limits"""
        print("\nüîç TEST 5: Content Processing Limits")
        print("Testing: Increased content processing limits (25000 chars for multiple articles, 20000 for single)")
        
        try:
            # Create a large test document to test processing limits
            large_content = """# Large Content Processing Test Document

This document is designed to test the increased content processing limits of the Enhanced Knowledge Engine.

""" + """## Section {}: Content Processing Analysis

This section contains detailed information about content processing capabilities and limitations. The Enhanced Knowledge Engine should be able to handle larger documents with improved processing limits.

### Subsection {}.1: Technical Details

The system now supports processing of documents up to 25,000 characters for multiple article generation and 20,000 characters for single article processing. This represents a significant improvement over previous limitations.

### Subsection {}.2: Implementation Benefits

With increased processing limits, users can upload more comprehensive documents and receive better structured, more detailed articles. This enhancement improves the overall user experience and content quality.

### Subsection {}.3: Performance Considerations

The increased limits are balanced with performance optimizations to ensure that processing remains efficient even with larger documents. The system uses intelligent chunking and parallel processing where appropriate.

""" * 15  # Repeat to create large content

            # Format the repeated sections with numbers
            formatted_content = large_content.format(*range(1, 46))  # Numbers for sections
            
            print(f"üìÑ Large document length: {len(formatted_content)} characters")
            
            # Upload the large document
            file_data = io.BytesIO(formatted_content.encode('utf-8'))
            files = {
                'file': ('large_content_test.txt', file_data, 'text/plain')
            }
            
            form_data = {
                'metadata': json.dumps({
                    "source": "review_requirements_test",
                    "test_type": "content_processing_limits",
                    "document_type": "large_content_test",
                    "original_filename": "large_content_test.txt"
                })
            }
            
            print("üì§ Uploading large content test document...")
            response = requests.post(
                f"{self.base_url}/content/upload",
                files=files,
                data=form_data,
                timeout=120  # Extended timeout for large content
            )
            
            if response.status_code != 200:
                print(f"‚ùå Large content upload failed - status code {response.status_code}")
                print(f"Response: {response.text}")
                self.test_results['content_processing_limits'] = False
                return False
            
            upload_data = response.json()
            extracted_length = upload_data.get('extracted_content_length', 0)
            chunks_created = upload_data.get('chunks_created', 0)
            
            print(f"‚úÖ Upload successful")
            print(f"üìä Extracted content length: {extracted_length} characters")
            print(f"üìä Chunks created: {chunks_created}")
            
            # Wait for processing
            print("‚è≥ Waiting for processing...")
            time.sleep(10)
            
            # Check if content was processed successfully
            if extracted_length >= 15000:  # Should handle large content
                print(f"‚úÖ EXCELLENT: Successfully processed {extracted_length} characters")
                self.test_results['content_processing_limits'] = True
                return True
            elif extracted_length >= 10000:
                print(f"‚ö†Ô∏è GOOD: Processed {extracted_length} characters (acceptable)")
                self.test_results['content_processing_limits'] = True
                return True
            else:
                print(f"‚ùå INSUFFICIENT: Only processed {extracted_length} characters")
                self.test_results['content_processing_limits'] = False
                return False
                
        except Exception as e:
            print(f"‚ùå Content processing limits test failed - {str(e)}")
            self.test_results['content_processing_limits'] = False
            return False

    def run_all_tests(self):
        """Run all review requirement tests"""
        print("üöÄ STARTING ENHANCED KNOWLEDGE ENGINE REVIEW REQUIREMENTS TESTING")
        print("=" * 80)
        
        tests = [
            ("Rich Document Processing", self.test_1_rich_document_processing),
            ("HTML Formatting Verification", self.test_2_html_formatting_verification),
            ("Enhanced List Processing", self.test_3_enhanced_list_processing),
            ("Image Embedding HTML Format", self.test_4_image_embedding_html_format),
            ("Content Processing Limits", self.test_5_content_processing_limits)
        ]
        
        passed_tests = 0
        total_tests = len(tests)
        
        for test_name, test_function in tests:
            try:
                print(f"\n{'='*60}")
                result = test_function()
                if result:
                    passed_tests += 1
                    print(f"‚úÖ {test_name}: PASSED")
                else:
                    print(f"‚ùå {test_name}: FAILED")
            except Exception as e:
                print(f"‚ùå {test_name}: FAILED with exception: {str(e)}")
                self.test_results[test_name.lower().replace(' ', '_')] = False
        
        # Print final summary
        print("\n" + "=" * 80)
        print("üèÅ ENHANCED KNOWLEDGE ENGINE REVIEW REQUIREMENTS TEST SUMMARY")
        print("=" * 80)
        
        for test_name, _ in tests:
            test_key = test_name.lower().replace(' ', '_')
            result = self.test_results.get(test_key, False)
            status = "‚úÖ PASS" if result else "‚ùå FAIL"
            print(f"{status} {test_name}")
        
        success_rate = (passed_tests / total_tests) * 100
        print(f"\nüìä Overall Success Rate: {success_rate:.1f}% ({passed_tests}/{total_tests})")
        
        if success_rate >= 80:
            print("üéâ EXCELLENT: Enhanced Knowledge Engine improvements are working very well!")
            print("‚úÖ The system meets the review requirements successfully.")
        elif success_rate >= 60:
            print("‚ö†Ô∏è GOOD: Most improvements are working, minor issues need attention.")
            print("‚úÖ The system largely meets the review requirements.")
        else:
            print("üö® NEEDS ATTENTION: Significant issues found with Enhanced Knowledge Engine.")
            print("‚ùå The system needs improvements to meet review requirements.")
        
        # Specific metrics summary
        print(f"\nüìã SPECIFIC METRICS SUMMARY:")
        print(f"   Rich Document Processing: {'‚úÖ' if self.test_results.get('rich_document_processing', False) else '‚ùå'}")
        print(f"   HTML vs Markdown Formatting: {'‚úÖ' if self.test_results.get('html_formatting_verification', False) else '‚ùå'}")
        print(f"   Enhanced List Processing: {'‚úÖ' if self.test_results.get('enhanced_list_processing', False) else '‚ùå'}")
        print(f"   HTML Image Embedding: {'‚úÖ' if self.test_results.get('image_embedding_html_format', False) else '‚ùå'}")
        print(f"   Content Processing Limits: {'‚úÖ' if self.test_results.get('content_processing_limits', False) else '‚ùå'}")
        
        return self.test_results

if __name__ == "__main__":
    tester = ReviewRequirementsTest()
    results = tester.run_all_tests()