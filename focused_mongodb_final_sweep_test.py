#!/usr/bin/env python3
"""
KE-PR9.5: MongoDB Final Sweep Progress Validation - Focused Test
Testing available MongoDB repository functionality and centralization progress

Focus on available endpoints and repository operations that are actually implemented.
"""

import os
import sys
import asyncio
import json
import requests
import time
import uuid
from datetime import datetime
from typing import Dict, List, Any, Optional

# Load environment variables
from dotenv import load_dotenv
load_dotenv()

# Get backend URL from frontend .env
def get_backend_url():
    """Get backend URL from frontend .env file"""
    frontend_env_path = os.path.join(os.path.dirname(__file__), 'frontend', '.env')
    if os.path.exists(frontend_env_path):
        with open(frontend_env_path, 'r') as f:
            for line in f:
                if line.startswith('REACT_APP_BACKEND_URL='):
                    return line.split('=', 1)[1].strip()
    return "http://localhost:8001"

BACKEND_URL = get_backend_url()
print(f"üåê Testing KE-PR9.5 MongoDB Final Sweep (Focused) at: {BACKEND_URL}")

class FocusedMongoDBTester:
    def __init__(self):
        self.backend_url = BACKEND_URL
        self.test_results = []
        self.total_tests = 0
        self.passed_tests = 0
        
    def log_test(self, test_name: str, passed: bool, details: str = ""):
        """Log test result"""
        self.total_tests += 1
        if passed:
            self.passed_tests += 1
            status = "‚úÖ PASS"
        else:
            status = "‚ùå FAIL"
            
        result = f"{status} - {test_name}"
        if details:
            result += f" | {details}"
            
        print(result)
        self.test_results.append({
            "test": test_name,
            "passed": passed,
            "details": details,
            "timestamp": datetime.now().isoformat()
        })
        
    def test_content_library_repository_operations(self):
        """Test 1: Content Library Repository Operations - Core CRUD functionality"""
        try:
            # Test content library listing
            list_response = requests.get(f"{self.backend_url}/api/content-library", timeout=30)
            
            if list_response.status_code != 200:
                self.log_test("Content Library Read Operations", False,
                             f"Content library listing failed: HTTP {list_response.status_code}")
                return False
            
            content_data = list_response.json()
            articles = content_data.get("articles", [])
            initial_count = len(articles)
            
            # Test article creation
            test_article = {
                "title": f"MongoDB Final Sweep Test {int(time.time())}",
                "content": "<h2>Repository Test</h2><p>Testing MongoDB repository pattern for KE-PR9.5 Final Sweep validation.</p>",
                "status": "published",
                "engine": "v2"
            }
            
            create_response = requests.post(
                f"{self.backend_url}/api/content-library",
                json=test_article,
                timeout=30
            )
            
            if create_response.status_code not in [200, 201]:
                self.log_test("Content Library Write Operations", False,
                             f"Article creation failed: HTTP {create_response.status_code}")
                return False
            
            # Verify article was created
            list_response2 = requests.get(f"{self.backend_url}/api/content-library", timeout=30)
            
            if list_response2.status_code != 200:
                self.log_test("Content Library Persistence Verification", False,
                             f"Content library re-listing failed: HTTP {list_response2.status_code}")
                return False
            
            content_data2 = list_response2.json()
            articles2 = content_data2.get("articles", [])
            final_count = len(articles2)
            
            if final_count <= initial_count:
                self.log_test("Content Library Data Persistence", False,
                             f"Article count did not increase: {initial_count} -> {final_count}")
                return False
            
            # Find the created article
            created_article = None
            for article in articles2:
                if article.get("title", "").startswith("MongoDB Final Sweep Test"):
                    created_article = article
                    break
            
            if not created_article:
                self.log_test("Content Library Article Retrieval", False,
                             "Created test article not found in listing")
                return False
            
            # Test article structure
            required_fields = ["id", "title", "content", "status"]
            missing_fields = [field for field in required_fields if field not in created_article]
            
            if missing_fields:
                self.log_test("Content Library Article Structure", False,
                             f"Missing required fields: {missing_fields}")
                return False
            
            self.log_test("Content Library Repository Operations", True,
                         f"CRUD operations working: create, read, persist, structure - Articles: {final_count}")
            return True
            
        except Exception as e:
            self.log_test("Content Library Repository Operations", False, f"Exception: {str(e)}")
            return False
    
    def test_mongodb_data_persistence(self):
        """Test 2: MongoDB Data Persistence - Verify data is properly stored and retrieved"""
        try:
            # Get initial article count
            initial_response = requests.get(f"{self.backend_url}/api/content-library", timeout=30)
            
            if initial_response.status_code != 200:
                self.log_test("MongoDB Data Persistence - Initial Read", False,
                             f"Initial read failed: HTTP {initial_response.status_code}")
                return False
            
            initial_data = initial_response.json()
            initial_articles = initial_data.get("articles", [])
            initial_count = len(initial_articles)
            
            # Create multiple test articles to verify persistence
            test_articles = []
            for i in range(3):
                article = {
                    "title": f"Persistence Test Article {i+1} - {int(time.time())}",
                    "content": f"<h2>Test Article {i+1}</h2><p>Testing MongoDB persistence for article {i+1}.</p>",
                    "status": "published",
                    "engine": "v2",
                    "metadata": {"test_batch": "persistence_validation", "article_number": i+1}
                }
                
                create_response = requests.post(
                    f"{self.backend_url}/api/content-library",
                    json=article,
                    timeout=30
                )
                
                if create_response.status_code in [200, 201]:
                    test_articles.append(article)
                    time.sleep(0.5)  # Small delay between creates
            
            if len(test_articles) < 2:
                self.log_test("MongoDB Data Persistence - Batch Creation", False,
                             f"Failed to create sufficient test articles: {len(test_articles)}/3")
                return False
            
            # Verify all articles were persisted
            final_response = requests.get(f"{self.backend_url}/api/content-library", timeout=30)
            
            if final_response.status_code != 200:
                self.log_test("MongoDB Data Persistence - Final Read", False,
                             f"Final read failed: HTTP {final_response.status_code}")
                return False
            
            final_data = final_response.json()
            final_articles = final_data.get("articles", [])
            final_count = len(final_articles)
            
            # Check if count increased appropriately
            count_increase = final_count - initial_count
            
            if count_increase < len(test_articles):
                self.log_test("MongoDB Data Persistence - Count Verification", False,
                             f"Article count increase insufficient: {count_increase} < {len(test_articles)}")
                return False
            
            # Verify article content integrity
            persisted_test_articles = [
                article for article in final_articles 
                if "Persistence Test Article" in article.get("title", "")
            ]
            
            if len(persisted_test_articles) < len(test_articles):
                self.log_test("MongoDB Data Persistence - Content Integrity", False,
                             f"Not all test articles found: {len(persisted_test_articles)}/{len(test_articles)}")
                return False
            
            # Verify data integrity (content matches what was sent)
            content_integrity_check = True
            for article in persisted_test_articles:
                if not article.get("content") or len(article.get("content", "")) < 50:
                    content_integrity_check = False
                    break
            
            if not content_integrity_check:
                self.log_test("MongoDB Data Persistence - Content Quality", False,
                             "Article content integrity check failed")
                return False
            
            self.log_test("MongoDB Data Persistence", True,
                         f"Data persistence verified: {count_increase} articles added, {len(persisted_test_articles)} test articles persisted")
            return True
            
        except Exception as e:
            self.log_test("MongoDB Data Persistence", False, f"Exception: {str(e)}")
            return False
    
    def test_system_health_and_stability(self):
        """Test 3: System Health & Stability - Ensure repository changes maintain system stability"""
        try:
            # Test basic system health
            health_response = requests.get(f"{self.backend_url}/api/health", timeout=30)
            
            if health_response.status_code != 200:
                self.log_test("System Health Check", False,
                             f"Health check failed: HTTP {health_response.status_code}")
                return False
            
            health_data = health_response.json()
            system_status = health_data.get("status", "unknown")
            
            # Test concurrent operations to verify stability
            concurrent_results = []
            start_time = time.time()
            
            for i in range(4):
                try:
                    response = requests.get(f"{self.backend_url}/api/content-library", timeout=30)
                    concurrent_results.append(response.status_code == 200)
                except:
                    concurrent_results.append(False)
                
                time.sleep(0.2)  # Small delay between requests
            
            end_time = time.time()
            total_time = end_time - start_time
            successful_concurrent = sum(concurrent_results)
            
            if successful_concurrent < 3:  # At least 3/4 should succeed
                self.log_test("System Stability - Concurrent Operations", False,
                             f"Concurrent operations failed: {successful_concurrent}/4")
                return False
            
            # Test system performance
            if total_time > 10:  # Should complete within 10 seconds
                self.log_test("System Stability - Performance", False,
                             f"Performance degraded: {total_time:.2f}s for 4 requests")
                return False
            
            # Test system recovery
            recovery_response = requests.get(f"{self.backend_url}/api/health", timeout=30)
            
            if recovery_response.status_code != 200:
                self.log_test("System Stability - Recovery", False,
                             f"System recovery failed: HTTP {recovery_response.status_code}")
                return False
            
            # Calculate stability score
            stability_indicators = [
                health_response.status_code == 200,
                successful_concurrent >= 3,
                total_time <= 10,
                recovery_response.status_code == 200
            ]
            
            stability_score = sum(stability_indicators)
            
            if stability_score < 3:
                self.log_test("System Health & Stability", False,
                             f"Stability issues detected: {stability_score}/4 indicators")
                return False
            
            self.log_test("System Health & Stability", True,
                         f"System stable: {stability_score}/4 indicators, {successful_concurrent}/4 concurrent ops, {total_time:.2f}s")
            return True
            
        except Exception as e:
            self.log_test("System Health & Stability", False, f"Exception: {str(e)}")
            return False
    
    def test_repository_performance_impact(self):
        """Test 4: Repository Performance Impact - Ensure repository pattern doesn't degrade performance"""
        try:
            # Test repository operation performance
            performance_results = []
            
            for i in range(5):
                start_time = time.time()
                
                response = requests.get(f"{self.backend_url}/api/content-library", timeout=30)
                
                end_time = time.time()
                request_time = end_time - start_time
                
                performance_results.append({
                    "success": response.status_code == 200,
                    "time": request_time
                })
                
                time.sleep(0.1)  # Small delay between requests
            
            # Analyze performance results
            successful_requests = sum(1 for result in performance_results if result["success"])
            
            if successful_requests < 4:  # At least 4/5 should succeed
                self.log_test("Repository Performance - Success Rate", False,
                             f"Performance test success rate too low: {successful_requests}/5")
                return False
            
            # Calculate average response time
            successful_times = [result["time"] for result in performance_results if result["success"]]
            avg_response_time = sum(successful_times) / len(successful_times) if successful_times else 999
            
            if avg_response_time > 5:  # Should average under 5 seconds
                self.log_test("Repository Performance - Response Time", False,
                             f"Average response time too high: {avg_response_time:.2f}s")
                return False
            
            # Test performance under load
            load_start_time = time.time()
            
            load_results = []
            for i in range(3):
                try:
                    response = requests.get(f"{self.backend_url}/api/content-library", timeout=30)
                    load_results.append(response.status_code == 200)
                except:
                    load_results.append(False)
            
            load_end_time = time.time()
            load_total_time = load_end_time - load_start_time
            load_success_rate = sum(load_results) / len(load_results) * 100
            
            if load_success_rate < 66:  # At least 66% should succeed under load
                self.log_test("Repository Performance - Load Test", False,
                             f"Load test success rate too low: {load_success_rate:.1f}%")
                return False
            
            self.log_test("Repository Performance Impact", True,
                         f"Performance acceptable: {avg_response_time:.2f}s avg, {successful_requests}/5 success, {load_success_rate:.1f}% under load")
            return True
            
        except Exception as e:
            self.log_test("Repository Performance Impact", False, f"Exception: {str(e)}")
            return False
    
    def test_error_handling_and_fallbacks(self):
        """Test 5: Error Handling & Fallbacks - Test repository error handling mechanisms"""
        try:
            # Test invalid request handling
            invalid_response = requests.get(f"{self.backend_url}/api/content-library/invalid-id-12345", timeout=30)
            
            # Should return 404 or 405 (method not allowed) - both indicate proper error handling
            invalid_handled = invalid_response.status_code in [404, 405, 400]
            
            # Test malformed data handling
            malformed_data = {"invalid": "data", "missing_required_fields": True}
            
            malformed_response = requests.post(
                f"{self.backend_url}/api/content-library",
                json=malformed_data,
                timeout=30
            )
            
            # Should return 400 or 422 for malformed data
            malformed_handled = malformed_response.status_code in [400, 422]
            
            # Test system recovery after errors
            recovery_response = requests.get(f"{self.backend_url}/api/content-library", timeout=30)
            system_recovered = recovery_response.status_code == 200
            
            # Test timeout handling
            timeout_handled = True
            try:
                timeout_response = requests.get(f"{self.backend_url}/api/content-library", timeout=1)
            except requests.exceptions.Timeout:
                timeout_handled = True  # Timeout is expected and handled
            except Exception:
                timeout_handled = False
            
            # Test error response format
            error_format_check = True
            if invalid_response.status_code in [404, 405, 400]:
                try:
                    error_data = invalid_response.json()
                    # Check if error response has proper structure
                    error_format_check = any(key in error_data for key in ["error", "message", "detail"])
                except:
                    error_format_check = False  # JSON parsing failed, but that's also acceptable
            
            # Calculate error handling score
            error_handling_indicators = [
                invalid_handled,
                malformed_handled,
                system_recovered,
                timeout_handled,
                error_format_check
            ]
            
            error_handling_score = sum(error_handling_indicators)
            
            if error_handling_score < 3:
                self.log_test("Error Handling & Fallbacks", False,
                             f"Error handling insufficient: {error_handling_score}/5 mechanisms working")
                return False
            
            self.log_test("Error Handling & Fallbacks", True,
                         f"Error handling working: {error_handling_score}/5 mechanisms functional")
            return True
            
        except Exception as e:
            self.log_test("Error Handling & Fallbacks", False, f"Exception: {str(e)}")
            return False
    
    def test_mixed_operations_workflow(self):
        """Test 6: Mixed Operations Workflow - Test integration between different system components"""
        try:
            # Test content processing workflow
            content_processing_available = False
            
            try:
                process_response = requests.post(
                    f"{self.backend_url}/api/content/process",
                    data={"content": "# Mixed Operations Test\n\nTesting mixed workflow operations.", "content_type": "markdown"},
                    timeout=60
                )
                content_processing_available = process_response.status_code == 200
            except:
                content_processing_available = False
            
            # Test asset operations (if available)
            assets_available = False
            
            try:
                assets_response = requests.get(f"{self.backend_url}/api/assets", timeout=30)
                assets_available = assets_response.status_code == 200
            except:
                assets_available = False
            
            # Test engine status (if available)
            engine_available = False
            
            try:
                engine_response = requests.get(f"{self.backend_url}/api/engine", timeout=30)
                engine_available = engine_response.status_code == 200
            except:
                engine_available = False
            
            # Test content library (should always be available)
            content_library_response = requests.get(f"{self.backend_url}/api/content-library", timeout=30)
            content_library_available = content_library_response.status_code == 200
            
            # Test AI assistance (if available)
            ai_available = False
            
            try:
                ai_response = requests.post(
                    f"{self.backend_url}/api/ai-assistance",
                    json={"text": "Test text for AI assistance", "mode": "complete"},
                    timeout=30
                )
                ai_available = ai_response.status_code == 200
            except:
                ai_available = False
            
            # Count available operations
            available_operations = sum([
                content_processing_available,
                assets_available,
                engine_available,
                content_library_available,
                ai_available
            ])
            
            if available_operations < 2:  # At least 2 operations should be available
                self.log_test("Mixed Operations Workflow", False,
                             f"Insufficient operations available: {available_operations}/5")
                return False
            
            # Test workflow integration
            workflow_integration_score = 0
            
            # If content processing and content library are both available, test integration
            if content_processing_available and content_library_available:
                workflow_integration_score += 1
            
            # If assets and content library are both available, test integration
            if assets_available and content_library_available:
                workflow_integration_score += 1
            
            # Content library should always contribute to integration
            if content_library_available:
                workflow_integration_score += 1
            
            if workflow_integration_score < 1:
                self.log_test("Mixed Operations Workflow Integration", False,
                             "No workflow integration detected")
                return False
            
            self.log_test("Mixed Operations Workflow", True,
                         f"Mixed operations working: {available_operations}/5 operations, integration score: {workflow_integration_score}")
            return True
            
        except Exception as e:
            self.log_test("Mixed Operations Workflow", False, f"Exception: {str(e)}")
            return False
    
    def run_all_tests(self):
        """Run all focused KE-PR9.5 MongoDB Final Sweep validation tests"""
        print("üéØ KE-PR9.5: MONGODB FINAL SWEEP PROGRESS VALIDATION (FOCUSED)")
        print("=" * 80)
        print("Testing available MongoDB repository functionality and centralization progress")
        print(f"Backend URL: {self.backend_url}")
        print(f"Test Start Time: {datetime.now().isoformat()}")
        print()
        
        # Run all tests
        tests = [
            self.test_content_library_repository_operations,
            self.test_mongodb_data_persistence,
            self.test_system_health_and_stability,
            self.test_repository_performance_impact,
            self.test_error_handling_and_fallbacks,
            self.test_mixed_operations_workflow
        ]
        
        for test in tests:
            try:
                test()
            except Exception as e:
                test_name = test.__name__.replace("test_", "").replace("_", " ").title()
                self.log_test(test_name, False, f"Test exception: {str(e)}")
            
            # Small delay between tests
            time.sleep(2)
        
        # Print summary
        print()
        print("=" * 80)
        print("üéØ KE-PR9.5: MONGODB FINAL SWEEP TEST SUMMARY (FOCUSED)")
        print("=" * 80)
        
        success_rate = (self.passed_tests / self.total_tests * 100) if self.total_tests > 0 else 0
        
        print(f"Total Tests: {self.total_tests}")
        print(f"Passed: {self.passed_tests}")
        print(f"Failed: {self.total_tests - self.passed_tests}")
        print(f"Success Rate: {success_rate:.1f}%")
        print()
        
        if success_rate >= 85:
            print("üéâ KE-PR9.5 MONGODB FINAL SWEEP: EXCELLENT - Strong MongoDB centralization progress!")
            print("‚úÖ Content Library Repository: Operations working correctly")
            print("‚úÖ MongoDB Data Persistence: Data properly stored and retrieved")
            print("‚úÖ System Stability: Repository changes maintain system stability")
            print("‚úÖ Performance Impact: Repository pattern performs well")
            print("‚úÖ Error Handling: Repository error handling functional")
            print("‚úÖ Mixed Operations: Workflow integration working")
        elif success_rate >= 70:
            print("‚úÖ KE-PR9.5 MONGODB FINAL SWEEP: GOOD - Most MongoDB operations working")
        elif success_rate >= 50:
            print("‚ö†Ô∏è KE-PR9.5 MONGODB FINAL SWEEP: PARTIAL - Some MongoDB centralization progress")
        else:
            print("‚ùå KE-PR9.5 MONGODB FINAL SWEEP: NEEDS ATTENTION - MongoDB centralization issues detected")
        
        print()
        print("Detailed Results:")
        for result in self.test_results:
            status = "‚úÖ" if result["passed"] else "‚ùå"
            print(f"{status} {result['test']}: {result['details']}")
        
        return success_rate

if __name__ == "__main__":
    tester = FocusedMongoDBTester()
    success_rate = tester.run_all_tests()
    
    # Exit with appropriate code
    sys.exit(0 if success_rate >= 70 else 1)